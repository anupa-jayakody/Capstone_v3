{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aafd4316",
      "metadata": {},
      "source": [
        "**Table of contents**<a id='toc0_'></a>    \n",
        "- [Libraries](#toc1_1_)    \n",
        "- [Option 1- Search by Ingredients](#toc2_)    \n",
        "  - [Tokenization](#toc2_1_)    \n",
        "  - [Modeling](#toc2_2_)    \n",
        "    - [Word2vec](#toc2_2_1_)    \n",
        "    - [Hyperparameter Evaluation](#toc2_2_2_)    \n",
        "    - [Word Embeddings](#toc2_2_3_)    \n",
        "  - [Vectorisation & Recommendation](#toc2_3_)    \n",
        "- [Option 2 : Search by Keywords](#toc3_)    \n",
        "    - [Tokenization](#toc3_1_1_)    \n",
        "    - [Modeling](#toc3_1_2_)    \n",
        "      - [Word2Vec](#toc3_1_2_1_)    \n",
        "      - [Hyperparameter Evaluation](#toc3_1_2_2_)    \n",
        "    - [Vectorization & Recommendation](#toc3_1_3_)    \n",
        "- [Option 3 : Search by Ingredients & Keywords both together](#toc4_)    \n",
        "  - [Tokenization](#toc4_1_)    \n",
        "  - [Modeling](#toc4_2_)    \n",
        "  - [Vectorization & Recommendation](#toc4_3_)    \n",
        "\n",
        "<!-- vscode-jupyter-toc-config\n",
        "\tnumbering=false\n",
        "\tanchor=true\n",
        "\tflat=false\n",
        "\tminLevel=1\n",
        "\tmaxLevel=6\n",
        "\t/vscode-jupyter-toc-config -->\n",
        "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eedb265b",
      "metadata": {},
      "source": [
        "## <a id='toc1_1_'></a>[Importing Dataset & Libraries](#toc0_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d811087",
      "metadata": {},
      "source": [
        "In thi section, I will explore Word2Vec vectorization for modeling and recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3ba7adee",
      "metadata": {
        "id": "3ba7adee"
      },
      "outputs": [],
      "source": [
        "#importing the basic libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "-3Uc8d669LhS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "-3Uc8d669LhS",
        "outputId": "52eba7d2-1481-4222-ab35-6038ed585fe4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\e312995\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#importing the word processing libraries\n",
        "\n",
        "\n",
        " #importing the regex library\n",
        "import re\n",
        "\n",
        "#importing the nltk library\n",
        "import nltk\n",
        "\n",
        "\n",
        "#lemmatizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "#  nltk stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#defining the stop words\n",
        "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
        "\n",
        "#library to handle punctuation\n",
        "import string\n",
        "\n",
        "#counter library\n",
        "from collections import Counter\n",
        "\n",
        "import spacy\n",
        "\n",
        "#speech tagging library\n",
        "from nltk import pos_tag\n",
        "\n",
        "#library for word embedding\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "62c380af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "62c380af",
        "outputId": "4a48149b-66c2-435e-f5b9-f4fcaf3b832a"
      },
      "outputs": [],
      "source": [
        "#loading the cleaned dataset\n",
        "recipes = pd.read_csv('../Docs/Datasets/recipes_cleaned.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "e5c557af",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(521766, 32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#checking\n",
        "recipes.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "57c11c39",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'RecipeId', 'Name', 'AuthorId', 'AuthorName', 'CookTime',\n",
              "       'PrepTime', 'TotalTime', 'DatePublished', 'Description', 'Images',\n",
              "       'RecipeCategory', 'Keywords', 'RecipeIngredientQuantities',\n",
              "       'RecipeIngredientParts', 'AggregatedRating', 'ReviewCount', 'Calories',\n",
              "       'FatContent', 'SaturatedFatContent', 'CholesterolContent',\n",
              "       'SodiumContent', 'CarbohydrateContent', 'FiberContent', 'SugarContent',\n",
              "       'ProteinContent', 'RecipeServings', 'RecipeYield', 'RecipeInstructions',\n",
              "       'length of ingredients', 'length_of_titles', 'Vegan/Not'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "recipes.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "192c2644",
      "metadata": {},
      "source": [
        "# <a id='toc2_'></a>[Option 1- Search by Ingredients](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "709cd08b",
      "metadata": {},
      "source": [
        "## <a id='toc2_1_'></a>[Tokenization](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c62f2a1",
      "metadata": {
        "id": "8c62f2a1"
      },
      "source": [
        "As the next step, I will be refining the ingredients data to avoid biases from different words and to have more consistency for comparsion of the input data vs the recipe data in the database"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NgAIBeBk9LhX",
      "metadata": {
        "id": "NgAIBeBk9LhX"
      },
      "source": [
        "In Sprint 1, I followed a process where I had multiple lines of codes for each data cleaning step, here I am creating one parser function which can be used to clean both ingredients and title columns. Furthermore in Sprint 1, my ingredients were cleaned in a way that an example of 'red cabbage' would produce 2 tokens red and cabbage seperately, but in the project context, these words should remain in the original form as red cabbage to make sense. So I have changed my cleaning steps to incorporate that."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_u4AMZOe9LhX",
      "metadata": {
        "id": "_u4AMZOe9LhX"
      },
      "source": [
        "As the recipes will usually contain alot of measuring terms and this will repeat, I will remove them from the list for the cleaning purpose to remove the biases from them."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8VPE8eel9Lhc",
      "metadata": {
        "id": "8VPE8eel9Lhc"
      },
      "source": [
        "Next I will\n",
        "- break each ingredient list to tokens/words\n",
        "- lower case\n",
        "- remove stop words\n",
        "- remove verbs\n",
        "- remove measuring word\n",
        "- remove characters and numbers\n",
        "\n",
        "All this is done to remove any impact from those words/tokens to the tool as the recommendation engine should only map for the true ingredients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "it4Ec-TQ9Lhc",
      "metadata": {
        "id": "it4Ec-TQ9Lhc"
      },
      "outputs": [],
      "source": [
        "def parser(input_keys): #function\n",
        "    \n",
        "    remove_= { 'oil', 'salt', 'pepper'}\n",
        "\n",
        "#defining measuring units\n",
        "\n",
        "    measurment_url= 'https://en.wikibooks.org/wiki/Cookbook:Units_of_measurement' #data source\n",
        "\n",
        "\n",
        "    measuring_words= ['ml', 'mL', 'milliliter', 'millilitre', 'cc' , 'cubic centimeter', 'l', 'L', 'liter', 'litre', 'dl', 'dL', 'deciliter', 'decilitre', 'teaspoon', 't' , 'tsp.',\n",
        "'tablespoon' , 'T', 'tbl', 'tbs', 'tbsp', 'fluid ounce', 'fl oz',  'gill', 'cup',  'c', 'pint', 'p', 'pt', 'fl pt',\n",
        "'quart', 'q', 'qt', 'fl qt', 'gallon' , 'g' , 'gal' , 'g', 'milligram', 'milligramme', 'g' , 'gram' , 'gramme', 'kg',\n",
        "'kilogram', 'kilogramme', 'pound', 'lb', 'ounce', 'oz', 'mm', 'millimeter', 'millimetre', 'cm' , 'centimeter', 'centimetre', 'm' , 'meter',\n",
        "'metre', 'inch', 'in', 'yard', '°C' , 'degree celsius','°F' ,'Farenheit', 'tsp']\n",
        "\n",
        "\n",
        "\n",
        "    ingredients_list = re.split(',', input_keys) #splitting the ingredients by commas\n",
        "\n",
        "    cleaned_ingredients = [] #new list to store cleaned ingredients\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer() #lemmatizer\n",
        "\n",
        "    for ingredient in ingredients_list:\n",
        "        items = re.split(' ', ingredient)  #splitting each ingredient by space to process and clean each individual word\n",
        "\n",
        "        items = [word for word in items if word.isalpha()] #filtering only letters\n",
        "\n",
        "        items = [word.lower() for word in items] #lowercasing\n",
        "\n",
        "        items = [lemmatizer.lemmatize(word) for word in items] #lemmatizing\n",
        "\n",
        "        items = [word for word in items if word not in ENGLISH_STOP_WORDS] #removing stop words\n",
        "\n",
        "        items = [word for word in items if word not in measuring_words] #removing measuring words\n",
        "\n",
        "        items = [word for word in items if word not in remove_]\n",
        "\n",
        "        if items:\n",
        "            cleaned_ingredients.append(' '.join(items) ) #joining the individual words of the ingredient seperated by space\n",
        "    \n",
        "\n",
        "    return cleaned_ingredients #return the list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Rwhw4k0J9Lhc",
      "metadata": {
        "id": "Rwhw4k0J9Lhc"
      },
      "source": [
        "Perfect, I have my ingredients seperated by a comma in original form."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a9978cef",
      "metadata": {},
      "source": [
        "## <a id='toc2_2_'></a>[Modeling](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0836154d",
      "metadata": {},
      "source": [
        "### <a id='toc2_2_1_'></a>[Word2vec](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "UDLVxtyp9Lhh",
      "metadata": {
        "id": "UDLVxtyp9Lhh"
      },
      "source": [
        "Since this is a text analysis, I will use Word2vec which will enable creating embeddings for each word which then can be  converted to a vector for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "b5d5b5e9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         blueberries, granulated sugar, vanilla yogurt,...\n",
              "1         saffron, milk, hot green chili peppers, onions...\n",
              "2         sugar, lemons, rind of, lemon, zest of, fresh ...\n",
              "3         extra firm tofu, eggplant, zucchini, mushrooms...\n",
              "4         plain tomato juice, cabbage, onion, carrots, c...\n",
              "                                ...                        \n",
              "521761    fresh ginger, unsalted butter, dark brown suga...\n",
              "521762    Dijon mustard, garlic, peppercorns, shallot, c...\n",
              "521763            half-and-half, heavy cream, brandy, sugar\n",
              "521764    wasabi paste, dill, English cucumber, smoked s...\n",
              "521765    hard-boiled eggs, breakfast sausage, panko bre...\n",
              "Name: RecipeIngredientParts, Length: 521766, dtype: object"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ingredients= recipes['RecipeIngredientParts']\n",
        "ingredients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "51qjy3W19Lhi",
      "metadata": {
        "id": "51qjy3W19Lhi",
        "outputId": "fb3c78cb-474c-4147-9835-8296bd0caa79"
      },
      "outputs": [],
      "source": [
        "#getting the parsed ingredients for the model\n",
        "ingredients= recipes['RecipeIngredientParts']\n",
        "ingredients_cleaned = ingredients.apply(parser)\n",
        "\n",
        "#word2vec model with starting parameters\n",
        "phrases_model=Word2Vec(sentences=ingredients_cleaned,min_count=1, sg=0, window=15, workers=8, vector_size=300, compute_loss=True)  #used min_count=1 to avoid any ingredient being missed out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c53a61ae",
      "metadata": {},
      "source": [
        "### <a id='toc2_2_2_'></a>[Hyperparameter Evaluation](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "860c6314",
      "metadata": {},
      "source": [
        "Now I will check different options with the model to check which gives the lowest compute loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "16474b49",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3379186.0"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loss with vector size 300\n",
        "phrases_model.get_latest_training_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "0916e482",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3237827.5"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#vector size 200\n",
        "phrases_model=Word2Vec(sentences=ingredients_cleaned,min_count=1, sg=0, window=15, workers=8, vector_size=200, compute_loss=True)\n",
        "phrases_model.get_latest_training_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c2be8978",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3303009.75"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#vector size 100\n",
        "phrases_model=Word2Vec(sentences=ingredients_cleaned,min_count=1, sg=0, window=15, workers=8, vector_size=100, compute_loss=True)\n",
        "phrases_model.get_latest_training_loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "012d1b77",
      "metadata": {},
      "source": [
        "I am also going to iterate through hs, window, vector sizes to see if I can pick the best hyperparamters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1f3bb3ba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2vec model #0: {'compute_loss': 35.260963439941406, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.012732823689778646, 'train_time_std': 0.00567042264213011}\n",
            "Word2vec model #1: {'compute_loss': 43.018375396728516, 'vector': 100, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.006684621175130208, 'train_time_std': 0.0009971383159784793}\n",
            "Word2vec model #2: {'compute_loss': 40.21577072143555, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.008651812871297201, 'train_time_std': 0.0019429537774844315}\n",
            "Word2vec model #3: {'compute_loss': 38.78705978393555, 'vector': 100, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.007415930430094401, 'train_time_std': 0.0006218066954818849}\n",
            "Word2vec model #4: {'compute_loss': 51.48100662231445, 'vector': 100, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.009589592615763346, 'train_time_std': 0.003002809766429137}\n",
            "Word2vec model #5: {'compute_loss': 63.46973419189453, 'vector': 100, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.007491191228230794, 'train_time_std': 0.006151371299613775}\n",
            "Word2vec model #6: {'compute_loss': 63.500179290771484, 'vector': 100, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.006377458572387695, 'train_time_std': 0.007303295576221297}\n",
            "Word2vec model #7: {'compute_loss': 60.64885711669922, 'vector': 100, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.006206989288330078, 'train_time_std': 0.008069341349286116}\n",
            "Word2vec model #8: {'compute_loss': 35.260963439941406, 'vector': 200, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.00543967882792155, 'train_time_std': 0.0076928675734004364}\n",
            "Word2vec model #9: {'compute_loss': 43.018375396728516, 'vector': 200, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.010784387588500977, 'train_time_std': 0.007628956233289532}\n",
            "Word2vec model #10: {'compute_loss': 40.209678649902344, 'vector': 200, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.007525126139322917, 'train_time_std': 0.006812679690093879}\n",
            "Word2vec model #11: {'compute_loss': 38.78705978393555, 'vector': 200, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.0046473344167073565, 'train_time_std': 0.006572323360990801}\n",
            "Word2vec model #12: {'compute_loss': 51.48100662231445, 'vector': 200, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.010745922724405924, 'train_time_std': 0.0076819565092796326}\n",
            "Word2vec model #13: {'compute_loss': 63.46973419189453, 'vector': 200, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.006433169047037761, 'train_time_std': 0.006885606810469192}\n",
            "Word2vec model #14: {'compute_loss': 63.500179290771484, 'vector': 200, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.010432720184326172, 'train_time_std': 0.007377197607552487}\n",
            "Word2vec model #15: {'compute_loss': 60.64885711669922, 'vector': 200, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.005350669225056966, 'train_time_std': 0.0075669889858479}\n",
            "Word2vec model #16: {'compute_loss': 35.260963439941406, 'vector': 300, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.0052280426025390625, 'train_time_std': 0.007393568753175075}\n",
            "Word2vec model #17: {'compute_loss': 43.018375396728516, 'vector': 300, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.010778109232584635, 'train_time_std': 0.007628121948734933}\n",
            "Word2vec model #18: {'compute_loss': 40.221858978271484, 'vector': 300, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.005250612894694011, 'train_time_std': 0.007425487966447325}\n",
            "Word2vec model #19: {'compute_loss': 38.78705978393555, 'vector': 300, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005594094594319661, 'train_time_std': 0.007911244444484884}\n",
            "Word2vec model #20: {'compute_loss': 51.48100662231445, 'vector': 300, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.011753161748250326, 'train_time_std': 0.00835618114861129}\n",
            "Word2vec model #21: {'compute_loss': 63.46973419189453, 'vector': 300, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.005260070164998372, 'train_time_std': 0.007438862566374782}\n",
            "Word2vec model #22: {'compute_loss': 63.51235580444336, 'vector': 300, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.005342006683349609, 'train_time_std': 0.007554738301880733}\n",
            "Word2vec model #23: {'compute_loss': 60.64885711669922, 'vector': 300, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.011157592137654623, 'train_time_std': 0.007912736655462008}\n",
            "Word2vec model #24: {'compute_loss': 506.5211486816406, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.005388816197713216, 'train_time_std': 0.007620936951941845}\n",
            "Word2vec model #25: {'compute_loss': 444.29071044921875, 'vector': 100, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.011400222778320312, 'train_time_std': 0.008141299206885708}\n",
            "Word2vec model #26: {'compute_loss': 549.046142578125, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.010713497797648111, 'train_time_std': 0.007577048634481919}\n",
            "Word2vec model #27: {'compute_loss': 478.2265930175781, 'vector': 100, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.01051489512125651, 'train_time_std': 0.0074355255083202575}\n",
            "Word2vec model #28: {'compute_loss': 855.756103515625, 'vector': 100, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.01222848892211914, 'train_time_std': 0.005361976735602624}\n",
            "Word2vec model #29: {'compute_loss': 749.67138671875, 'vector': 100, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.010472615559895834, 'train_time_std': 0.007405282556903889}\n",
            "Word2vec model #30: {'compute_loss': 932.3141479492188, 'vector': 100, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.010647773742675781, 'train_time_std': 0.007531735973723125}\n",
            "Word2vec model #31: {'compute_loss': 812.5990600585938, 'vector': 100, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.006906668345133464, 'train_time_std': 0.009767504044500684}\n",
            "Word2vec model #32: {'compute_loss': 506.5271911621094, 'vector': 200, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.010594765345255533, 'train_time_std': 0.007492361085788243}\n",
            "Word2vec model #33: {'compute_loss': 444.2176818847656, 'vector': 200, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.011437654495239258, 'train_time_std': 0.008087823463407764}\n",
            "Word2vec model #34: {'compute_loss': 548.9976196289062, 'vector': 200, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.011364301045735678, 'train_time_std': 0.008103811356952486}\n",
            "Word2vec model #35: {'compute_loss': 478.18402099609375, 'vector': 200, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.016707499821980793, 'train_time_std': 0.01403392868936103}\n",
            "Word2vec model #36: {'compute_loss': 855.7255249023438, 'vector': 200, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.010674635569254557, 'train_time_std': 0.007551426303409591}\n",
            "Word2vec model #37: {'compute_loss': 749.6165161132812, 'vector': 200, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.011342446009318033, 'train_time_std': 0.008067313300779163}\n",
            "Word2vec model #38: {'compute_loss': 932.2653198242188, 'vector': 200, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.010725100835164389, 'train_time_std': 0.007586043683054548}\n",
            "Word2vec model #39: {'compute_loss': 812.6112060546875, 'vector': 200, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.011076927185058594, 'train_time_std': 0.007861261117790567}\n",
            "Word2vec model #40: {'compute_loss': 506.4664001464844, 'vector': 300, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.011536518732706705, 'train_time_std': 0.008254789718288856}\n",
            "Word2vec model #41: {'compute_loss': 444.1872863769531, 'vector': 300, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.005279858907063802, 'train_time_std': 0.007466848073786016}\n",
            "Word2vec model #42: {'compute_loss': 548.9307250976562, 'vector': 300, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.010840574900309244, 'train_time_std': 0.0076654644933086165}\n",
            "Word2vec model #43: {'compute_loss': 478.11114501953125, 'vector': 300, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.0052598317464192705, 'train_time_std': 0.007438525391586695}\n",
            "Word2vec model #44: {'compute_loss': 855.6646728515625, 'vector': 300, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.012082258860270182, 'train_time_std': 0.008685978356932914}\n",
            "Word2vec model #45: {'compute_loss': 749.5922241210938, 'vector': 300, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.01098179817199707, 'train_time_std': 0.007767243006788802}\n",
            "Word2vec model #46: {'compute_loss': 932.2227172851562, 'vector': 300, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.010474205017089844, 'train_time_std': 0.0074063850893185115}\n",
            "Word2vec model #47: {'compute_loss': 812.4954833984375, 'vector': 300, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.011820316314697266, 'train_time_std': 0.008463898430318622}\n",
            "Word2vec model #48: {'compute_loss': 13.399166107177734, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.011298418045043945, 'train_time_std': 0.007994384767138096}\n",
            "Word2vec model #49: {'compute_loss': 10.578289031982422, 'vector': 100, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.010632594426472982, 'train_time_std': 0.007522294390090703}\n",
            "Word2vec model #50: {'compute_loss': 14.104385375976562, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.006014585494995117, 'train_time_std': 0.00850590837907459}\n",
            "Word2vec model #51: {'compute_loss': 11.988727569580078, 'vector': 100, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005273739496866862, 'train_time_std': 0.007458193920891779}\n",
            "Word2vec model #52: {'compute_loss': 16.220043182373047, 'vector': 100, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.00531760851542155, 'train_time_std': 0.007520234081899814}\n",
            "Word2vec model #53: {'compute_loss': 13.399166107177734, 'vector': 100, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.010633071263631185, 'train_time_std': 0.007520741945897128}\n",
            "Word2vec model #54: {'compute_loss': 16.925262451171875, 'vector': 100, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.0052403608957926435, 'train_time_std': 0.007410989450559577}\n",
            "Word2vec model #55: {'compute_loss': 14.80960464477539, 'vector': 100, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.006868124008178711, 'train_time_std': 0.009712994120426595}\n",
            "Word2vec model #56: {'compute_loss': 13.399166107177734, 'vector': 200, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.004859129587809245, 'train_time_std': 0.006871846964408221}\n",
            "Word2vec model #57: {'compute_loss': 10.578289031982422, 'vector': 200, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.010419289271036783, 'train_time_std': 0.007367551904735049}\n",
            "Word2vec model #58: {'compute_loss': 14.104385375976562, 'vector': 200, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.005223433176676433, 'train_time_std': 0.00738705004060539}\n",
            "Word2vec model #59: {'compute_loss': 11.988727569580078, 'vector': 200, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005247036616007487, 'train_time_std': 0.007420430344626017}\n",
            "Word2vec model #60: {'compute_loss': 16.220043182373047, 'vector': 200, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.007581551869710286, 'train_time_std': 0.006671163207991099}\n",
            "Word2vec model #61: {'compute_loss': 13.399166107177734, 'vector': 200, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.010416905085245768, 'train_time_std': 0.007365876649984862}\n",
            "Word2vec model #62: {'compute_loss': 16.925262451171875, 'vector': 200, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.00520777702331543, 'train_time_std': 0.0073649088961876665}\n",
            "Word2vec model #63: {'compute_loss': 14.80960464477539, 'vector': 200, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.005220492680867513, 'train_time_std': 0.007382891551552315}\n",
            "Word2vec model #64: {'compute_loss': 13.399166107177734, 'vector': 300, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.010561704635620117, 'train_time_std': 0.007469002374835816}\n",
            "Word2vec model #65: {'compute_loss': 10.578289031982422, 'vector': 300, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.007139841715494792, 'train_time_std': 0.0065387973480844136}\n",
            "Word2vec model #66: {'compute_loss': 14.104385375976562, 'vector': 300, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.005288044611612956, 'train_time_std': 0.007478424408177008}\n",
            "Word2vec model #67: {'compute_loss': 11.988727569580078, 'vector': 300, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005222797393798828, 'train_time_std': 0.007386150907837157}\n",
            "Word2vec model #68: {'compute_loss': 16.220043182373047, 'vector': 300, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.005311806996663411, 'train_time_std': 0.0075120294953896945}\n",
            "Word2vec model #69: {'compute_loss': 13.399166107177734, 'vector': 300, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.012275060017903646, 'train_time_std': 0.008928759759781897}\n",
            "Word2vec model #70: {'compute_loss': 16.925262451171875, 'vector': 300, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.005304654439290364, 'train_time_std': 0.007305888757035351}\n",
            "Word2vec model #71: {'compute_loss': 14.80960464477539, 'vector': 300, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.005747000376383464, 'train_time_std': 0.008127485875244776}\n",
            "Word2vec model #72: {'compute_loss': 259.2165832519531, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.01041849454243978, 'train_time_std': 0.007367007832472252}\n",
            "Word2vec model #73: {'compute_loss': 298.7336730957031, 'vector': 100, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.005255937576293945, 'train_time_std': 0.0074330182033812715}\n",
            "Word2vec model #74: {'compute_loss': 230.24774169921875, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.00660856564839681, 'train_time_std': 0.009345923167795716}\n",
            "Word2vec model #75: {'compute_loss': 289.65704345703125, 'vector': 100, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005285978317260742, 'train_time_std': 0.007475502226680253}\n",
            "Word2vec model #76: {'compute_loss': 424.62939453125, 'vector': 100, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.010607242584228516, 'train_time_std': 0.0075016697815615055}\n",
            "Word2vec model #77: {'compute_loss': 489.5895690917969, 'vector': 100, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.005249977111816406, 'train_time_std': 0.007424588833679093}\n",
            "Word2vec model #78: {'compute_loss': 376.5035400390625, 'vector': 100, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.0053862730662028, 'train_time_std': 0.007617340420868914}\n",
            "Word2vec model #79: {'compute_loss': 480.5307922363281, 'vector': 100, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.012115955352783203, 'train_time_std': 0.008808457354650075}\n",
            "Word2vec model #80: {'compute_loss': 259.3140869140625, 'vector': 200, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.005279064178466797, 'train_time_std': 0.0074657241578257256}\n",
            "Word2vec model #81: {'compute_loss': 298.849365234375, 'vector': 200, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.011229594548543295, 'train_time_std': 0.007941461987356936}\n",
            "Word2vec model #82: {'compute_loss': 230.27816772460938, 'vector': 200, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.007639567057291667, 'train_time_std': 0.0064761413731671885}\n",
            "Word2vec model #83: {'compute_loss': 289.693603515625, 'vector': 200, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.0039037863413492837, 'train_time_std': 0.005520787588543003}\n",
            "Word2vec model #84: {'compute_loss': 424.7266540527344, 'vector': 200, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.010596911112467447, 'train_time_std': 0.007493839343873056}\n",
            "Word2vec model #85: {'compute_loss': 489.6990051269531, 'vector': 200, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.0052712758382161455, 'train_time_std': 0.0074547097814148785}\n",
            "Word2vec model #86: {'compute_loss': 376.52789306640625, 'vector': 200, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.0052979787190755205, 'train_time_std': 0.00749247335768064}\n",
            "Word2vec model #87: {'compute_loss': 480.5915222167969, 'vector': 200, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.012114127477010092, 'train_time_std': 0.008806454204527308}\n",
            "Word2vec model #88: {'compute_loss': 259.2897033691406, 'vector': 300, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.005212545394897461, 'train_time_std': 0.00737165239194941}\n",
            "Word2vec model #89: {'compute_loss': 298.81890869140625, 'vector': 300, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.0052947998046875, 'train_time_std': 0.007487977693839477}\n",
            "Word2vec model #90: {'compute_loss': 230.29034423828125, 'vector': 300, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.010780413945515951, 'train_time_std': 0.007622969441061464}\n",
            "Word2vec model #91: {'compute_loss': 289.693603515625, 'vector': 300, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005269686381022136, 'train_time_std': 0.007452461949494296}\n",
            "Word2vec model #92: {'compute_loss': 424.66583251953125, 'vector': 300, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.0068064530690511065, 'train_time_std': 0.006733882080919885}\n",
            "Word2vec model #93: {'compute_loss': 489.68084716796875, 'vector': 300, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.010898590087890625, 'train_time_std': 0.007720311387848567}\n",
            "Word2vec model #94: {'compute_loss': 376.5339660644531, 'vector': 300, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.005474090576171875, 'train_time_std': 0.007741533134481016}\n",
            "Word2vec model #95: {'compute_loss': 480.5673522949219, 'vector': 300, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.010857979456583658, 'train_time_std': 0.007677759640659429}\n",
            "Word2vec model #96: {'compute_loss': 12.693946838378906, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.006102561950683594, 'train_time_std': 0.005368819702058416}\n",
            "Word2vec model #97: {'compute_loss': 10.578289031982422, 'vector': 100, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.005231380462646484, 'train_time_std': 0.007398289200208295}\n",
            "Word2vec model #98: {'compute_loss': 9.167850494384766, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.010752042134602865, 'train_time_std': 0.007602890751953766}\n",
            "Word2vec model #99: {'compute_loss': 17.630481719970703, 'vector': 100, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005421161651611328, 'train_time_std': 0.0076666803315256675}\n",
            "Word2vec model #100: {'compute_loss': 15.514823913574219, 'vector': 100, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.005273977915445964, 'train_time_std': 0.007458531095679865}\n",
            "Word2vec model #101: {'compute_loss': 13.399166107177734, 'vector': 100, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.006638129552205403, 'train_time_std': 0.006690410034954804}\n",
            "Word2vec model #102: {'compute_loss': 11.28350830078125, 'vector': 100, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.010564247767130533, 'train_time_std': 0.0074703664039571125}\n",
            "Word2vec model #103: {'compute_loss': 21.861797332763672, 'vector': 100, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.005377769470214844, 'train_time_std': 0.007605314520093806}\n",
            "Word2vec model #104: {'compute_loss': 12.693946838378906, 'vector': 200, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.00531315803527832, 'train_time_std': 0.007513940152522188}\n",
            "Word2vec model #105: {'compute_loss': 10.578289031982422, 'vector': 200, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.010590632756551107, 'train_time_std': 0.007488893371087118}\n",
            "Word2vec model #106: {'compute_loss': 9.167850494384766, 'vector': 200, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.006777763366699219, 'train_time_std': 0.006640815262824106}\n",
            "Word2vec model #107: {'compute_loss': 17.630481719970703, 'vector': 200, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005277156829833984, 'train_time_std': 0.007463026759521028}\n",
            "Word2vec model #108: {'compute_loss': 15.514823913574219, 'vector': 200, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.005217234293619792, 'train_time_std': 0.007378283496115123}\n",
            "Word2vec model #109: {'compute_loss': 13.399166107177734, 'vector': 200, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.00523988405863444, 'train_time_std': 0.007410315100983403}\n",
            "Word2vec model #110: {'compute_loss': 11.28350830078125, 'vector': 200, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.01237797737121582, 'train_time_std': 0.009021364136438038}\n",
            "Word2vec model #111: {'compute_loss': 21.861797332763672, 'vector': 200, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.005264838536580403, 'train_time_std': 0.0074456060621365255}\n",
            "Word2vec model #112: {'compute_loss': 12.693946838378906, 'vector': 300, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.00537109375, 'train_time_std': 0.007595873626027366}\n",
            "Word2vec model #113: {'compute_loss': 10.578289031982422, 'vector': 300, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.005336761474609375, 'train_time_std': 0.007547320456542816}\n",
            "Word2vec model #114: {'compute_loss': 9.167850494384766, 'vector': 300, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.01044313112894694, 'train_time_std': 0.007384424249642846}\n",
            "Word2vec model #115: {'compute_loss': 17.630481719970703, 'vector': 300, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.006876309712727864, 'train_time_std': 0.006513923035719294}\n",
            "Word2vec model #116: {'compute_loss': 15.514823913574219, 'vector': 300, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.005220095316569011, 'train_time_std': 0.00738232959357217}\n",
            "Word2vec model #117: {'compute_loss': 13.399166107177734, 'vector': 300, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.005323489507039388, 'train_time_std': 0.007528551060005965}\n",
            "Word2vec model #118: {'compute_loss': 11.28350830078125, 'vector': 300, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.011128822962443033, 'train_time_std': 0.00787769510148501}\n",
            "Word2vec model #119: {'compute_loss': 21.861797332763672, 'vector': 300, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.005925655364990234, 'train_time_std': 0.008380142183118082}\n",
            "Word2vec model #120: {'compute_loss': 137.6331024169922, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.011017958323160807, 'train_time_std': 0.007820321312671233}\n",
            "Word2vec model #121: {'compute_loss': 180.05567932128906, 'vector': 100, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.005564371744791667, 'train_time_std': 0.007869209987570017}\n",
            "Word2vec model #122: {'compute_loss': 122.18548583984375, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.010653257369995117, 'train_time_std': 0.00753365891750064}\n",
            "Word2vec model #123: {'compute_loss': 136.9583740234375, 'vector': 100, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005427042643229167, 'train_time_std': 0.007674997309631817}\n",
            "Word2vec model #124: {'compute_loss': 221.65122985839844, 'vector': 100, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.006545305252075195, 'train_time_std': 0.009256459457356592}\n",
            "Word2vec model #125: {'compute_loss': 291.632568359375, 'vector': 100, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.0052258968353271484, 'train_time_std': 0.00739053418008229}\n",
            "Word2vec model #126: {'compute_loss': 190.74964904785156, 'vector': 100, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.01044313112894694, 'train_time_std': 0.007384603589540779}\n",
            "Word2vec model #127: {'compute_loss': 218.15565490722656, 'vector': 100, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.005245208740234375, 'train_time_std': 0.00741784533791735}\n",
            "Word2vec model #128: {'compute_loss': 137.6269989013672, 'vector': 200, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.01061264673868815, 'train_time_std': 0.007504564637724612}\n",
            "Word2vec model #129: {'compute_loss': 180.0374298095703, 'vector': 200, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.007123629252115886, 'train_time_std': 0.006504381505817053}\n",
            "Word2vec model #130: {'compute_loss': 122.19767761230469, 'vector': 200, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.005282481511433919, 'train_time_std': 0.007470556996454975}\n",
            "Word2vec model #131: {'compute_loss': 136.92794799804688, 'vector': 200, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.0052309830983479815, 'train_time_std': 0.00739772724222815}\n",
            "Word2vec model #132: {'compute_loss': 221.6330108642578, 'vector': 200, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.010521252950032553, 'train_time_std': 0.0074396497379676995}\n",
            "Word2vec model #133: {'compute_loss': 291.5838317871094, 'vector': 200, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.0070874691009521484, 'train_time_std': 0.010023194925466775}\n",
            "Word2vec model #134: {'compute_loss': 190.72528076171875, 'vector': 200, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.005397399266560872, 'train_time_std': 0.007633075244312982}\n",
            "Word2vec model #135: {'compute_loss': 218.11912536621094, 'vector': 200, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.010565757751464844, 'train_time_std': 0.00747212228817048}\n",
            "Word2vec model #136: {'compute_loss': 137.6269989013672, 'vector': 300, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.005605856577555339, 'train_time_std': 0.007927878400697181}\n",
            "Word2vec model #137: {'compute_loss': 180.0435028076172, 'vector': 300, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.005212148030598958, 'train_time_std': 0.007371090433969265}\n",
            "Word2vec model #138: {'compute_loss': 122.17938232421875, 'vector': 300, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.011772950490315756, 'train_time_std': 0.00847823399975031}\n",
            "Word2vec model #139: {'compute_loss': 136.92181396484375, 'vector': 300, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005276123682657878, 'train_time_std': 0.00746156566877265}\n",
            "Word2vec model #140: {'compute_loss': 221.65127563476562, 'vector': 300, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.006165107091267903, 'train_time_std': 0.008718778061953612}\n",
            "Word2vec model #141: {'compute_loss': 291.6142578125, 'vector': 300, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.009926716486612955, 'train_time_std': 0.0071386686540345174}\n",
            "Word2vec model #142: {'compute_loss': 190.72525024414062, 'vector': 300, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.0067984263102213545, 'train_time_std': 0.009614426690709117}\n",
            "Word2vec model #143: {'compute_loss': 218.11300659179688, 'vector': 300, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.01045846939086914, 'train_time_std': 0.007395292762167764}\n",
            "Word2vec model #144: {'compute_loss': 151.06268310546875, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.0052220821380615234, 'train_time_std': 0.0073851393834728956}\n",
            "Word2vec model #145: {'compute_loss': 153.91403198242188, 'vector': 100, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.011562108993530273, 'train_time_std': 0.008290697107332734}\n",
            "Word2vec model #146: {'compute_loss': 127.08537292480469, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.006048123041788737, 'train_time_std': 0.00855333763259885}\n",
            "Word2vec model #147: {'compute_loss': 240.88699340820312, 'vector': 100, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.010511398315429688, 'train_time_std': 0.007433283128262809}\n",
            "Word2vec model #148: {'compute_loss': 242.94163513183594, 'vector': 100, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.005303621292114258, 'train_time_std': 0.007500453160998702}\n",
            "Word2vec model #149: {'compute_loss': 246.449462890625, 'vector': 100, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.010613441467285156, 'train_time_std': 0.0075054982510961}\n",
            "Word2vec model #150: {'compute_loss': 204.11834716796875, 'vector': 100, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.006940682729085286, 'train_time_std': 0.009815607647601119}\n",
            "Word2vec model #151: {'compute_loss': 388.0059814453125, 'vector': 100, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.010456085205078125, 'train_time_std': 0.007393712698407309}\n",
            "Word2vec model #152: {'compute_loss': 151.11141967773438, 'vector': 200, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.0052178700764973955, 'train_time_std': 0.007379182628883357}\n",
            "Word2vec model #153: {'compute_loss': 153.9201202392578, 'vector': 200, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.005360762278238933, 'train_time_std': 0.007581262718543589}\n",
            "Word2vec model #154: {'compute_loss': 127.0975570678711, 'vector': 200, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.005244811375935872, 'train_time_std': 0.007417283379937204}\n",
            "Word2vec model #155: {'compute_loss': 240.9418487548828, 'vector': 200, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.01223317782084147, 'train_time_std': 0.008913681908015733}\n",
            "Word2vec model #156: {'compute_loss': 242.9781951904297, 'vector': 200, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.005282402038574219, 'train_time_std': 0.007470444604858946}\n",
            "Word2vec model #157: {'compute_loss': 246.45550537109375, 'vector': 200, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.005241552988688151, 'train_time_std': 0.007412675324500013}\n",
            "Word2vec model #158: {'compute_loss': 204.11219787597656, 'vector': 200, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.010456720987955729, 'train_time_std': 0.007394082291674148}\n",
            "Word2vec model #159: {'compute_loss': 388.07904052734375, 'vector': 200, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.007091522216796875, 'train_time_std': 0.010028926896864257}\n",
            "Word2vec model #160: {'compute_loss': 151.09312438964844, 'vector': 300, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.00521389643351237, 'train_time_std': 0.007373563049081903}\n",
            "Word2vec model #161: {'compute_loss': 153.9627685546875, 'vector': 300, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.010784228642781576, 'train_time_std': 0.007632059238749185}\n",
            "Word2vec model #162: {'compute_loss': 127.10973358154297, 'vector': 300, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.005258083343505859, 'train_time_std': 0.0074360527764740555}\n",
            "Word2vec model #163: {'compute_loss': 240.9600830078125, 'vector': 300, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005229949951171875, 'train_time_std': 0.007396266151479772}\n",
            "Word2vec model #164: {'compute_loss': 242.9659881591797, 'vector': 300, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.012161016464233398, 'train_time_std': 0.008825254385645041}\n",
            "Word2vec model #165: {'compute_loss': 246.51039123535156, 'vector': 300, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.0052725474039713545, 'train_time_std': 0.007456508046951343}\n",
            "Word2vec model #166: {'compute_loss': 204.16098022460938, 'vector': 300, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.005216360092163086, 'train_time_std': 0.007377047188558804}\n",
            "Word2vec model #167: {'compute_loss': 388.0972595214844, 'vector': 300, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.010503689448038736, 'train_time_std': 0.00742772954597902}\n",
            "Word2vec model #168: {'compute_loss': 59.986263275146484, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.00710304578145345, 'train_time_std': 0.01004522367828847}\n",
            "Word2vec model #169: {'compute_loss': 43.018375396728516, 'vector': 100, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.005252281824747722, 'train_time_std': 0.007427848189963935}\n",
            "Word2vec model #170: {'compute_loss': 63.49408721923828, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.00526579221089681, 'train_time_std': 0.007446954761288874}\n",
            "Word2vec model #171: {'compute_loss': 43.04882049560547, 'vector': 100, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.010452667872111002, 'train_time_std': 0.007391184204852441}\n",
            "Word2vec model #172: {'compute_loss': 86.81497955322266, 'vector': 100, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.005253156026204427, 'train_time_std': 0.007429084497520255}\n",
            "Word2vec model #173: {'compute_loss': 64.17495727539062, 'vector': 100, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.0070781707763671875, 'train_time_std': 0.006699103558055704}\n",
            "Word2vec model #174: {'compute_loss': 93.13140869140625, 'vector': 100, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.010486125946044922, 'train_time_std': 0.007414881181088362}\n",
            "Word2vec model #175: {'compute_loss': 63.51844024658203, 'vector': 100, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.005344072977701823, 'train_time_std': 0.007557660483377488}\n",
            "Word2vec model #176: {'compute_loss': 59.98626708984375, 'vector': 200, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.0053967634836832685, 'train_time_std': 0.007632176111544749}\n",
            "Word2vec model #177: {'compute_loss': 43.018375396728516, 'vector': 200, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.010497331619262695, 'train_time_std': 0.007422830939936848}\n",
            "Word2vec model #178: {'compute_loss': 63.506263732910156, 'vector': 200, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.00684364636739095, 'train_time_std': 0.006587543521762325}\n",
            "Word2vec model #179: {'compute_loss': 43.03664016723633, 'vector': 200, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.005246400833129883, 'train_time_std': 0.007419531211857786}\n",
            "Word2vec model #180: {'compute_loss': 86.81494140625, 'vector': 200, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.00522462526957194, 'train_time_std': 0.007388735914545825}\n",
            "Word2vec model #181: {'compute_loss': 64.17495727539062, 'vector': 200, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.010552008946736654, 'train_time_std': 0.007462315801673067}\n",
            "Word2vec model #182: {'compute_loss': 93.16184997558594, 'vector': 200, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.007160743077596028, 'train_time_std': 0.00660819874559769}\n",
            "Word2vec model #183: {'compute_loss': 63.50626754760742, 'vector': 200, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.005296627680460612, 'train_time_std': 0.007490562700548146}\n",
            "Word2vec model #184: {'compute_loss': 59.98017501831055, 'vector': 300, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.010630448659261068, 'train_time_std': 0.007521160513487314}\n",
            "Word2vec model #185: {'compute_loss': 43.018375396728516, 'vector': 300, 'window': 13, 'hs_val': 0, 'train_time_mean': 0.0052064259847005205, 'train_time_std': 0.007362998239055173}\n",
            "Word2vec model #186: {'compute_loss': 63.49408721923828, 'vector': 300, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.005738417307535808, 'train_time_std': 0.008115347582873638}\n",
            "Word2vec model #187: {'compute_loss': 43.06708526611328, 'vector': 300, 'window': 18, 'hs_val': 0, 'train_time_mean': 0.0064915815989176435, 'train_time_std': 0.006850526523616437}\n",
            "Word2vec model #188: {'compute_loss': 86.80887603759766, 'vector': 300, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.010451316833496094, 'train_time_std': 0.007390201528031559}\n",
            "Word2vec model #189: {'compute_loss': 64.17495727539062, 'vector': 300, 'window': 13, 'hs_val': 1, 'train_time_mean': 0.005216439565022786, 'train_time_std': 0.007377159580154833}\n",
            "Word2vec model #190: {'compute_loss': 93.13749694824219, 'vector': 300, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.010543346405029297, 'train_time_std': 0.007455272656887757}\n",
            "Word2vec model #191: {'compute_loss': 63.54888153076172, 'vector': 300, 'window': 18, 'hs_val': 1, 'train_time_mean': 0.007222811381022136, 'train_time_std': 0.00644965050034184}\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "you must first build vocabulary before training the model",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     18\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 19\u001b[0m     w2v_model \u001b[38;5;241m=\u001b[39m Word2Vec(\n\u001b[0;32m     20\u001b[0m         data,\n\u001b[0;32m     21\u001b[0m         compute_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m     22\u001b[0m         window\u001b[38;5;241m=\u001b[39m window,\n\u001b[0;32m     23\u001b[0m         vector_size\u001b[38;5;241m=\u001b[39mvector,\n\u001b[0;32m     24\u001b[0m         hs\u001b[38;5;241m=\u001b[39mhs_val,\n\u001b[0;32m     25\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed_val,\n\u001b[0;32m     26\u001b[0m     )\n\u001b[0;32m     27\u001b[0m     time_taken_list\u001b[38;5;241m.\u001b[39mappend(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time)\n\u001b[0;32m     29\u001b[0m time_taken_list \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(time_taken_list)\n",
            "File \u001b[1;32mc:\\Users\\e312995\\AppData\\Local\\anaconda3\\Lib\\site-packages\\gensim\\models\\word2vec.py:430\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[1;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39m(epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_vocab(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, trim_rule\u001b[38;5;241m=\u001b[39mtrim_rule)\n\u001b[1;32m--> 430\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[0;32m    431\u001b[0m         corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, total_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_count,\n\u001b[0;32m    432\u001b[0m         total_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_total_words, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs, start_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha,\n\u001b[0;32m    433\u001b[0m         end_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha, compute_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trim_rule \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\e312995\\AppData\\Local\\anaconda3\\Lib\\site-packages\\gensim\\models\\word2vec.py:1045\u001b[0m, in \u001b[0;36mWord2Vec.train\u001b[1;34m(self, corpus_iterable, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha \u001b[38;5;241m=\u001b[39m end_alpha \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m=\u001b[39m epochs\n\u001b[1;32m-> 1045\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_training_sanity(epochs\u001b[38;5;241m=\u001b[39mepochs, total_examples\u001b[38;5;241m=\u001b[39mtotal_examples, total_words\u001b[38;5;241m=\u001b[39mtotal_words)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_corpus_sanity(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, passes\u001b[38;5;241m=\u001b[39mepochs)\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_lifecycle_event(\n\u001b[0;32m   1049\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1050\u001b[0m     msg\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1054\u001b[0m     ),\n\u001b[0;32m   1055\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\e312995\\AppData\\Local\\anaconda3\\Lib\\site-packages\\gensim\\models\\word2vec.py:1543\u001b[0m, in \u001b[0;36mWord2Vec._check_training_sanity\u001b[1;34m(self, epochs, total_examples, total_words, **kwargs)\u001b[0m\n\u001b[0;32m   1540\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEffective \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malpha\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m higher than previous training cycles\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1542\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mkey_to_index:  \u001b[38;5;66;03m# should be set by `build_vocab`\u001b[39;00m\n\u001b[1;32m-> 1543\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou must first build vocabulary before training the model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mvectors):\n\u001b[0;32m   1545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou must initialize vectors before training the model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[1;31mRuntimeError\u001b[0m: you must first build vocabulary before training the model"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "train_time_values = []\n",
        "seed_val = 42\n",
        "\n",
        "hs_values = [0, 1]\n",
        "vector_values= [100,200,300]\n",
        "window_values= [10,13,15,18]\n",
        "\n",
        "\n",
        "\n",
        "for data in ingredients_cleaned:\n",
        "    for vector in vector_values:\n",
        "        for hs_val in hs_values:\n",
        "            for window in window_values:\n",
        "                time_taken_list = []\n",
        "                for i in range(3):\n",
        "                    start_time = time.time()\n",
        "                    w2v_model = Word2Vec(\n",
        "                        data,\n",
        "                        compute_loss=True,\n",
        "                        window= window,\n",
        "                        vector_size=vector,\n",
        "                        hs=hs_val,\n",
        "                        seed=seed_val,\n",
        "                    )\n",
        "                    time_taken_list.append(time.time() - start_time)\n",
        "\n",
        "                time_taken_list = np.array(time_taken_list)\n",
        "                time_mean = np.mean(time_taken_list)\n",
        "                time_std = np.std(time_taken_list)\n",
        "\n",
        "                model_result = {\n",
        "                \n",
        "                    'compute_loss': w2v_model.get_latest_training_loss(),\n",
        "                    'vector': vector,\n",
        "                    'window': window,\n",
        "                    'hs_val': hs_val,\n",
        "                    'train_time_mean': time_mean,\n",
        "                    'train_time_std': time_std,\n",
        "                }\n",
        "                print(\"Word2vec model #%i: %s\" % (len(train_time_values), model_result))\n",
        "                train_time_values.append(model_result)\n",
        "\n",
        "train_times_table = pd.DataFrame(train_time_values)\n",
        "train_times_table = train_times_table.sort_values(\n",
        "    by=['train_data',  'hs', 'compute_loss'],\n",
        "    ascending=[False, False, False],\n",
        ")\n",
        "print(train_times_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed8d7e5e",
      "metadata": {},
      "source": [
        "As per above, vector size 300, window size=15 and hs_val=0 gives the lowest loss factor, Combining with the earlier training losses, I will proceed with below. \n",
        "\n",
        "Final model selection:\n",
        " - vector size= 300\n",
        " - hs= 0\n",
        " - window= 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3ffbeb36",
      "metadata": {},
      "outputs": [],
      "source": [
        "#final model\n",
        "phrases_model=Word2Vec(sentences=ingredients_cleaned,min_count=1, sg=0, window=15, workers=8, vector_size=300, compute_loss=True, hs=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0f12d5d2",
      "metadata": {},
      "outputs": [],
      "source": [
        "#saving the model\n",
        "phrases_model.save('../Models/Word2Vec/phrases_model_new(op1).bin')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12d3f056",
      "metadata": {},
      "source": [
        "### <a id='toc2_2_3_'></a>[Word Embeddings](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "512edd47",
      "metadata": {},
      "source": [
        "Checking similar words to different ingredients if the model has been trained well.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "20e70481",
      "metadata": {},
      "outputs": [],
      "source": [
        "#getting the word embeddings to compare different ingredients\n",
        "embeddings= {word: phrases_model.wv[word] for word in phrases_model.wv.index_to_key} "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a279c375",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('yellow onion', 0.7783803343772888), ('spanish onion', 0.7026346325874329), ('sweet onion', 0.6776735186576843), ('cooking onion', 0.5974043011665344), ('small onion', 0.5848987698554993)]\n"
          ]
        }
      ],
      "source": [
        "print(phrases_model.wv.most_similar(u'onion', topn=5)) #checking the most similar results for onion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "nqCREoUv9Lhi",
      "metadata": {
        "id": "nqCREoUv9Lhi",
        "outputId": "6754aa52-9dbe-457d-b543-f220392af1b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('garlic clove', 0.9395226836204529), ('minced garlic clove', 0.8867267966270447), ('fresh garlic', 0.8198416829109192), ('fresh garlic clove', 0.7923763394355774), ('bulb garlic', 0.6134870052337646)]\n"
          ]
        }
      ],
      "source": [
        "print(phrases_model.wv.most_similar(u'garlic', topn=5)) #again checkin the most similar words to garlic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "216956d7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('penne', 0.7471584677696228),\n",
              " ('dry pasta', 0.7409198880195618),\n",
              " ('rigatoni pasta', 0.7240394353866577),\n",
              " ('pasta shell', 0.7223595976829529),\n",
              " ('penne pasta', 0.714836597442627),\n",
              " ('parmigiano', 0.6961620450019836),\n",
              " ('pecorino romano cheese', 0.659299373626709),\n",
              " ('parmesan cheese', 0.6543958187103271),\n",
              " ('ziti pasta', 0.6520697474479675),\n",
              " ('farfalle pasta', 0.64471036195755)]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "phrases_model.wv.most_similar(['cheese', 'pasta'], topn=10) #checking for cheese pasta"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RclKh9Gk9Lhi",
      "metadata": {
        "id": "RclKh9Gk9Lhi"
      },
      "source": [
        "I will try to use a tile map to show the similarity of a few ingredients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "0Q7LfVBv9Lhi",
      "metadata": {
        "id": "0Q7LfVBv9Lhi",
        "outputId": "d40edfe7-67f0-459f-b5e3-e275cabbec6f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2000x500 with 4 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "word_list = ['onion', 'garlic', 'tuna', 'chicken'] #example\n",
        "\n",
        "plt.subplots(len(word_list), 1, figsize=(20, 5)) #plot\n",
        "\n",
        "for i, word in enumerate(word_list): #for loop to get each word in the list\n",
        "    plt.subplot(len(word_list), 1, i + 1) #subplot\n",
        "    plt.imshow(np.tile(embeddings[word], (10, 1))) #data\n",
        "    plt.xticks([]) #no xticks\n",
        "    plt.yticks([]) #no yticks\n",
        "    plt.title(f\"\\\"{word}\\\" embedding vector\") #title\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dDqvkyL39Lhi",
      "metadata": {
        "id": "dDqvkyL39Lhi"
      },
      "source": [
        "It is visible that words represent different distributions. Looks good. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c03dfbe",
      "metadata": {},
      "source": [
        "## <a id='toc2_3_'></a>[Vectorisation & Recommendation](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "242d95fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# user Input Processing\n",
        "user_input = 'egg', 'rice'  # User's input\n",
        "\n",
        "def recommender(user_input):\n",
        "\n",
        "    #parsing the user input\n",
        "    user_input = ','.join(map(str, user_input)) #converting to str, mapping and joining by the ','\n",
        "    \n",
        "    user_input.split(',')\n",
        "\n",
        "    user_input=parser(user_input)\n",
        "    \n",
        "\n",
        "\n",
        "# mean Embeddings for User Input\n",
        "    user_mean_vector =np.mean([phrases_model.wv[ingredient] for ingredient in user_input if ingredient in phrases_model.wv] or [np.zeros(300)], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "# check if user_mean_vector contains NaN values\n",
        "    if np.isnan(user_mean_vector).any():\n",
        "        print(\"User input vectors contain NaN values.\")\n",
        "\n",
        "\n",
        "    else:\n",
        "\n",
        "    # mean ingredient vectors for each recipe\n",
        "        recipe_vectors = [np.mean([phrases_model.wv[sub_ingredient] for sub_ingredient in ingredient if sub_ingredient in phrases_model.wv] or [np.zeros(300)], axis=0) for ingredient in ingredients_cleaned]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Check if any recipe vector contains NaN values\n",
        "        if not recipe_vectors:\n",
        "            print('nothing obtained for recipe vectors')\n",
        "\n",
        "        else:\n",
        "        \n",
        "        # cosine similarity between user mean vector and recipe mean vectors\n",
        "            cosine_similarities = cosine_similarity([user_mean_vector], recipe_vectors)\n",
        "\n",
        "\n",
        "        # indices of top N most similar recipes\n",
        "            top_recipes = np.argsort(cosine_similarities[0])[::-1][:5]\n",
        "\n",
        "\n",
        "\n",
        "            recommendation= pd.DataFrame( columns=['Title','Ingredients', 'Category', 'Calories', 'Time', 'Score'] ) #dataframe with columns\n",
        "\n",
        "    \n",
        "            for i in top_recipes: #defining the data for each recommendation\n",
        "\n",
        "            \n",
        "                title = recipes['Name'].iloc[i]\n",
        "                calories = recipes['Calories'].iloc[i]\n",
        "                time= recipes['TotalTime'].iloc[i]\n",
        "                ingredients = recipes['RecipeIngredientParts'].iloc[i]\n",
        "                category= recipes['RecipeCategory'].iloc[i]\n",
        "                score= cosine_similarities[0][i]\n",
        "                \n",
        "                recommendation = pd.concat([recommendation,pd.DataFrame(\n",
        "                                    {'Title': [title], \n",
        "                                    'Ingredients': [ingredients], \n",
        "                                    'Category' : [category],\n",
        "                                    'Calories': [calories], \n",
        "                                     'Time': [time],\n",
        "                                     'Score': [score]})], \n",
        "                                        ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return recommendation  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "1f6ada1c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\e312995\\AppData\\Local\\Temp\\ipykernel_30044\\3972358604.py:62: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  recommendation = pd.concat([recommendation,pd.DataFrame(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Ingredients</th>\n",
              "      <th>Category</th>\n",
              "      <th>Calories</th>\n",
              "      <th>Time</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Tibetan Cabbage Salad (Tangtse)</td>\n",
              "      <td>white cabbage, daikon radish, carrot, salt</td>\n",
              "      <td>Vegetable</td>\n",
              "      <td>52.5</td>\n",
              "      <td>PT10M</td>\n",
              "      <td>0.885739</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vinegret. Russian Vegetarian Salad</td>\n",
              "      <td>carrot, beet, pickled cucumbers, cabbage, kidn...</td>\n",
              "      <td>Potato</td>\n",
              "      <td>65.8</td>\n",
              "      <td>PT50M</td>\n",
              "      <td>0.879665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Et-Su-Put (Boiled Pork With Vegetables)</td>\n",
              "      <td>water, potatoes, carrot, cabbage</td>\n",
              "      <td>Pork</td>\n",
              "      <td>548.9</td>\n",
              "      <td>PT3H10M</td>\n",
              "      <td>0.877808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Coleslaw With Herbed Vinaigrette</td>\n",
              "      <td>cabbage, carrot, onion, Herbed Vinaigrette</td>\n",
              "      <td>&lt; 60 Mins</td>\n",
              "      <td>44.9</td>\n",
              "      <td>PT35M</td>\n",
              "      <td>0.871626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Easy Ramen Stir-Fry</td>\n",
              "      <td>onion, cabbage, carrot</td>\n",
              "      <td>Lunch/Snacks</td>\n",
              "      <td>34.0</td>\n",
              "      <td>PT20M</td>\n",
              "      <td>0.870758</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Title  \\\n",
              "0          Tibetan Cabbage Salad (Tangtse)   \n",
              "1       Vinegret. Russian Vegetarian Salad   \n",
              "2  Et-Su-Put (Boiled Pork With Vegetables)   \n",
              "3         Coleslaw With Herbed Vinaigrette   \n",
              "4                      Easy Ramen Stir-Fry   \n",
              "\n",
              "                                         Ingredients      Category  Calories  \\\n",
              "0         white cabbage, daikon radish, carrot, salt     Vegetable      52.5   \n",
              "1  carrot, beet, pickled cucumbers, cabbage, kidn...        Potato      65.8   \n",
              "2                   water, potatoes, carrot, cabbage          Pork     548.9   \n",
              "3         cabbage, carrot, onion, Herbed Vinaigrette     < 60 Mins      44.9   \n",
              "4                             onion, cabbage, carrot  Lunch/Snacks      34.0   \n",
              "\n",
              "      Time     Score  \n",
              "0    PT10M  0.885739  \n",
              "1    PT50M  0.879665  \n",
              "2  PT3H10M  0.877808  \n",
              "3    PT35M  0.871626  \n",
              "4    PT20M  0.870758  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_input = 'cabbage', 'carrot'\n",
        "\n",
        "\n",
        "recommender(user_input)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a463ba",
      "metadata": {},
      "source": [
        "# <a id='toc3_'></a>[Option 2 : Search by Keywords](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6044cc0d",
      "metadata": {},
      "source": [
        "I now will give the option to the user to search recipes using keywords present in the recipe database. For that I wil use the columns containing key attributes, 'Title', 'RecipeCategory', 'Keywords' and follow the same process as earlier."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9569b9f7",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_1_'></a>[Tokenization](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "bd967a66",
      "metadata": {},
      "outputs": [],
      "source": [
        "#combining the 3 columns data to one\n",
        "recipes['text_data']= recipes[['Name', 'RecipeCategory', 'Keywords']].astype(str).agg(','.join, axis=1) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "2237b109",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0         Low-Fat Berry Blue Frozen Dessert,Frozen Desse...\n",
              "1         Biryani,Chicken Breast,Chicken Thigh & Leg, Ch...\n",
              "2         Best Lemonade,Beverages,Low Protein, Low Chole...\n",
              "3         Carina's Tofu-Vegetable Kebabs,Soy/Tofu,Beans,...\n",
              "4         Cabbage Soup,Vegetable,Low Protein, Vegan, Low...\n",
              "                                ...                        \n",
              "521761     Meg's Fresh Ginger Gingerbread,Dessert,< 4 Hours\n",
              "521762    Roast Prime Rib au Poivre with Mixed Peppercor...\n",
              "521763    Kirshwasser Ice Cream,Ice Cream,Dessert, < 4 H...\n",
              "521764    Quick & Easy Asian Cucumber Salmon Rolls,Canad...\n",
              "521765          Spicy Baked Scotch Eggs,Breakfast,< 60 Mins\n",
              "Name: text_data, Length: 521766, dtype: object"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#sanity check\n",
        "recipes['text_data']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "ceae0790",
      "metadata": {},
      "outputs": [],
      "source": [
        "#parser\n",
        "\n",
        "text_data= recipes['text_data']\n",
        "\n",
        "def parser_text(input_keys): #function\n",
        "\n",
        "\n",
        "#defining measuring units\n",
        "\n",
        "    measurment_url= 'https://en.wikibooks.org/wiki/Cookbook:Units_of_measurement' #data source\n",
        "\n",
        "    remove_= ['mins']#removing the word mins to avoid biases and give results based on true mins in digit format\n",
        "\n",
        "\n",
        "    measuring_words= ['ml', 'mL', 'milliliter', 'millilitre', 'cc' , 'cubic centimeter', 'l', 'L', 'liter', 'litre', 'dl', 'dL', 'deciliter', 'decilitre', 'teaspoon', 't' , 'tsp.',\n",
        "'tablespoon' , 'T', 'tbl', 'tbs', 'tbsp', 'fluid ounce', 'fl oz',  'gill', 'cup',  'c', 'pint', 'p', 'pt', 'fl pt',\n",
        "'quart', 'q', 'qt', 'fl qt', 'gallon' , 'g' , 'gal' , 'g', 'milligram', 'milligramme', 'g' , 'gram' , 'gramme', 'kg',\n",
        "'kilogram', 'kilogramme', 'pound', 'lb', 'ounce', 'oz', 'mm', 'millimeter', 'millimetre', 'cm' , 'centimeter', 'centimetre', 'm' , 'meter',\n",
        "'metre', 'inch', 'in', 'yard', '°C' , 'degree celsius','°F' ,'Farenheit', 'tsp']\n",
        "\n",
        "\n",
        "\n",
        "    ingredients_list = re.split(',', input_keys) #splitting the ingredients by commas\n",
        "    ingredients_list = re.split(' ', input_keys) #splitting the ingredients by commas\n",
        "\n",
        "    cleaned_ingredients = [] #new list to store cleaned ingredients\n",
        "\n",
        "    lemmatizer = WordNetLemmatizer() #lemmatizer\n",
        "\n",
        "    for ingredient in ingredients_list:\n",
        "        items = re.split(',', ingredient)  #splitting each ingredient by space to process and clean each individual word\n",
        "\n",
        "        items = [word for word in items if word.isalpha()] #filtering only letters\n",
        "\n",
        "\n",
        "        items = [word.lower() for word in items] #lowercasing\n",
        "\n",
        "        items = [lemmatizer.lemmatize(word) for word in items] #lemmatizing\n",
        "\n",
        "        items = [word for word in items if word not in ENGLISH_STOP_WORDS] #removing stop words\n",
        "\n",
        "        items = [word for word in items if word not in measuring_words] #removing measuring words\n",
        "\n",
        "        if items:\n",
        "            cleaned_ingredients.append(','.join(items) ) #joining the individual words of the ingredient seperated by space\n",
        "        #cleaned_ingredients= ' '.join(cleaned_ingredients) #joining the ingreidents back seprated by commas\n",
        "\n",
        "\n",
        "    return cleaned_ingredients #return the list\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba6ff863",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_2_'></a>[Modeling](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5baeedea",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_2_1_'></a>[Word2Vec](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f55cd60c",
      "metadata": {},
      "outputs": [],
      "source": [
        "#applying the parser to the text data to be used in model training\n",
        "text_data_cleaned = text_data.apply(parser_text)\n",
        "recipes['TextDataCleaned']= text_data_cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b9e1679b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3185942.0"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#vector size 100\n",
        "phrases_model_2=Word2Vec(sentences=text_data_cleaned,min_count=1, sg=0, window=20, workers=8, vector_size=100, compute_loss=True) #word2vec model, used min_count=1 to avoid any ingredient being missed out\n",
        "phrases_model_2.get_latest_training_loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "241c69b5",
      "metadata": {},
      "source": [
        "#### <a id='toc3_1_2_2_'></a>[Hyperparameter Evaluation](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "025850b4",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3151367.75"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#vector size 200\n",
        "phrases_model_2=Word2Vec(sentences=text_data_cleaned,min_count=1, sg=0, window=20, workers=8, vector_size=200, compute_loss=True)\n",
        "phrases_model_2.get_latest_training_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "0941520e",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3166027.0"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#vector size 300\n",
        "phrases_model_2=Word2Vec(sentences=text_data_cleaned,min_count=1, sg=0, window=20, workers=8, vector_size=300, compute_loss=True)\n",
        "phrases_model_2.get_latest_training_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "126baec0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2vec model #0: {'compute_loss': 75.53761291503906, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.016642332077026367, 'train_time_std': 0.0067546619758141295}\n",
            "Word2vec model #1: {'compute_loss': 81.18545532226562, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.011443376541137695, 'train_time_std': 0.0010282996909788563}\n",
            "Word2vec model #2: {'compute_loss': 114.36109924316406, 'vector': 100, 'window': 20, 'hs_val': 0, 'train_time_mean': 0.0111234982808431, 'train_time_std': 0.0022528345037700977}\n",
            "Word2vec model #3: {'compute_loss': 101.71585083007812, 'vector': 100, 'window': 25, 'hs_val': 0, 'train_time_mean': 0.0075329939524332685, 'train_time_std': 0.0013193936297923024}\n",
            "Word2vec model #4: {'compute_loss': 81.18545532226562, 'vector': 100, 'window': 30, 'hs_val': 0, 'train_time_mean': 0.0063122908274332685, 'train_time_std': 0.00047024643778554833}\n",
            "Word2vec model #5: {'compute_loss': 112.95668029785156, 'vector': 100, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.009024222691853842, 'train_time_std': 0.0012556163709483465}\n",
            "Word2vec model #6: {'compute_loss': 122.12449645996094, 'vector': 100, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.00802938143412272, 'train_time_std': 0.004747058484981659}\n",
            "Word2vec model #7: {'compute_loss': 170.17660522460938, 'vector': 100, 'window': 20, 'hs_val': 1, 'train_time_mean': 0.008960564931233725, 'train_time_std': 0.003753844262228361}\n",
            "Word2vec model #8: {'compute_loss': 149.74977111816406, 'vector': 100, 'window': 25, 'hs_val': 1, 'train_time_mean': 0.008451302846272787, 'train_time_std': 0.0007722753867504514}\n",
            "Word2vec model #9: {'compute_loss': 122.12449645996094, 'vector': 100, 'window': 30, 'hs_val': 1, 'train_time_mean': 0.010477304458618164, 'train_time_std': 0.0025272700094662328}\n",
            "Word2vec model #10: {'compute_loss': 75.543701171875, 'vector': 200, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.008599122365315756, 'train_time_std': 0.0003712758517823118}\n",
            "Word2vec model #11: {'compute_loss': 81.18544006347656, 'vector': 200, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.006289879480997722, 'train_time_std': 0.006344047030515599}\n",
            "Word2vec model #12: {'compute_loss': 114.37327575683594, 'vector': 200, 'window': 20, 'hs_val': 0, 'train_time_mean': 0.008442163467407227, 'train_time_std': 0.0021253553093383473}\n",
            "Word2vec model #13: {'compute_loss': 101.70974731445312, 'vector': 200, 'window': 25, 'hs_val': 0, 'train_time_mean': 0.006519873936971028, 'train_time_std': 0.006605194610369268}\n",
            "Word2vec model #14: {'compute_loss': 81.18544006347656, 'vector': 200, 'window': 30, 'hs_val': 0, 'train_time_mean': 0.006456216176350911, 'train_time_std': 0.009130468478208024}\n",
            "Word2vec model #15: {'compute_loss': 112.9627685546875, 'vector': 200, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.006421248118082683, 'train_time_std': 0.0006691415346575942}\n",
            "Word2vec model #16: {'compute_loss': 122.13667297363281, 'vector': 200, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.003984848658243815, 'train_time_std': 0.005635427016492633}\n",
            "Word2vec model #17: {'compute_loss': 170.1826934814453, 'vector': 200, 'window': 20, 'hs_val': 1, 'train_time_mean': 0.009923060735066732, 'train_time_std': 0.005021021015124862}\n",
            "Word2vec model #18: {'compute_loss': 149.7558135986328, 'vector': 200, 'window': 25, 'hs_val': 1, 'train_time_mean': 0.006483157475789388, 'train_time_std': 0.007239900543042368}\n",
            "Word2vec model #19: {'compute_loss': 122.13667297363281, 'vector': 200, 'window': 30, 'hs_val': 1, 'train_time_mean': 0.007429043451944987, 'train_time_std': 0.00822037504056019}\n",
            "Word2vec model #20: {'compute_loss': 75.53761291503906, 'vector': 300, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.009434143702189127, 'train_time_std': 0.0010089511137178575}\n",
            "Word2vec model #21: {'compute_loss': 81.19764709472656, 'vector': 300, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.006314277648925781, 'train_time_std': 0.00026891086281308224}\n",
            "Word2vec model #22: {'compute_loss': 114.36720275878906, 'vector': 300, 'window': 20, 'hs_val': 0, 'train_time_mean': 0.0043888092041015625, 'train_time_std': 0.0026545120805730317}\n",
            "Word2vec model #23: {'compute_loss': 101.734130859375, 'vector': 300, 'window': 25, 'hs_val': 0, 'train_time_mean': 0.00546725591023763, 'train_time_std': 0.0077318674572225176}\n",
            "Word2vec model #24: {'compute_loss': 81.19764709472656, 'vector': 300, 'window': 30, 'hs_val': 0, 'train_time_mean': 0.009627024332682291, 'train_time_std': 0.004296232673196491}\n",
            "Word2vec model #25: {'compute_loss': 112.95059204101562, 'vector': 300, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.007069985071818034, 'train_time_std': 0.006794015595210368}\n",
            "Word2vec model #26: {'compute_loss': 122.14277648925781, 'vector': 300, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.008192857106526693, 'train_time_std': 0.011586449634634842}\n",
            "Word2vec model #27: {'compute_loss': 170.18881225585938, 'vector': 300, 'window': 20, 'hs_val': 1, 'train_time_mean': 0.011787494023640951, 'train_time_std': 0.0037227521353803837}\n",
            "Word2vec model #28: {'compute_loss': 149.7741241455078, 'vector': 300, 'window': 25, 'hs_val': 1, 'train_time_mean': 0.013493220011393229, 'train_time_std': 0.0020446857069749296}\n",
            "Word2vec model #29: {'compute_loss': 122.14277648925781, 'vector': 300, 'window': 30, 'hs_val': 1, 'train_time_mean': 0.01092998186747233, 'train_time_std': 0.003501961456569061}\n",
            "Word2vec model #30: {'compute_loss': 76.95411682128906, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.009001731872558594, 'train_time_std': 0.007450946081733897}\n",
            "Word2vec model #31: {'compute_loss': 89.67240905761719, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.010535717010498047, 'train_time_std': 0.0017122556412658735}\n",
            "Word2vec model #32: {'compute_loss': 120.74456787109375, 'vector': 100, 'window': 20, 'hs_val': 0, 'train_time_mean': 0.012987534205118815, 'train_time_std': 0.0028493858494852992}\n",
            "Word2vec model #33: {'compute_loss': 93.186279296875, 'vector': 100, 'window': 25, 'hs_val': 0, 'train_time_mean': 0.011355876922607422, 'train_time_std': 0.00633673575254856}\n",
            "Word2vec model #34: {'compute_loss': 89.67240905761719, 'vector': 100, 'window': 30, 'hs_val': 0, 'train_time_mean': 0.01101978619893392, 'train_time_std': 0.010058262307807334}\n",
            "Word2vec model #35: {'compute_loss': 119.31591796875, 'vector': 100, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.025491635004679363, 'train_time_std': 0.020511008505997238}\n",
            "Word2vec model #36: {'compute_loss': 137.6880645751953, 'vector': 100, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.02926945686340332, 'train_time_std': 0.021153379798404766}\n",
            "Word2vec model #37: {'compute_loss': 186.42091369628906, 'vector': 100, 'window': 20, 'hs_val': 1, 'train_time_mean': 0.019124666849772137, 'train_time_std': 0.006818037530822957}\n",
            "Word2vec model #38: {'compute_loss': 145.43313598632812, 'vector': 100, 'window': 25, 'hs_val': 1, 'train_time_mean': 0.009303092956542969, 'train_time_std': 0.004532617040767201}\n",
            "Word2vec model #39: {'compute_loss': 137.6880645751953, 'vector': 100, 'window': 30, 'hs_val': 1, 'train_time_mean': 0.0167392094930013, 'train_time_std': 0.004406873406831652}\n",
            "Word2vec model #40: {'compute_loss': 76.91758728027344, 'vector': 200, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.01410818099975586, 'train_time_std': 0.011023426244914846}\n",
            "Word2vec model #41: {'compute_loss': 89.69065856933594, 'vector': 200, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.008101145426432291, 'train_time_std': 0.005871958215992013}\n",
            "Word2vec model #42: {'compute_loss': 120.72627258300781, 'vector': 200, 'window': 20, 'hs_val': 0, 'train_time_mean': 0.01106421152750651, 'train_time_std': 0.007826546333040968}\n",
            "Word2vec model #43: {'compute_loss': 93.19236755371094, 'vector': 200, 'window': 25, 'hs_val': 0, 'train_time_mean': 0.017183701197306316, 'train_time_std': 0.0006780989142752201}\n",
            "Word2vec model #44: {'compute_loss': 89.69065856933594, 'vector': 200, 'window': 30, 'hs_val': 0, 'train_time_mean': 0.01541900634765625, 'train_time_std': 0.00334538685737418}\n",
            "Word2vec model #45: {'compute_loss': 119.27931213378906, 'vector': 200, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.011841376622517904, 'train_time_std': 0.006990762257445979}\n",
            "Word2vec model #46: {'compute_loss': 137.73068237304688, 'vector': 200, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.011251131693522135, 'train_time_std': 0.00830484703484274}\n",
            "Word2vec model #47: {'compute_loss': 186.41476440429688, 'vector': 200, 'window': 20, 'hs_val': 1, 'train_time_mean': 0.01766053835550944, 'train_time_std': 0.002452570952930938}\n",
            "Word2vec model #48: {'compute_loss': 145.451416015625, 'vector': 200, 'window': 25, 'hs_val': 1, 'train_time_mean': 0.010063568751017252, 'train_time_std': 0.007117685617734164}\n",
            "Word2vec model #49: {'compute_loss': 137.73068237304688, 'vector': 200, 'window': 30, 'hs_val': 1, 'train_time_mean': 0.01662103335062663, 'train_time_std': 0.005229368843645002}\n",
            "Word2vec model #50: {'compute_loss': 76.93585205078125, 'vector': 300, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.012735287348429361, 'train_time_std': 0.0008808165520421686}\n",
            "Word2vec model #51: {'compute_loss': 89.70285034179688, 'vector': 300, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.010382652282714844, 'train_time_std': 0.002609504066071496}\n",
            "Word2vec model #52: {'compute_loss': 120.72628784179688, 'vector': 300, 'window': 20, 'hs_val': 0, 'train_time_mean': 0.01176126797993978, 'train_time_std': 0.003855032451568526}\n",
            "Word2vec model #53: {'compute_loss': 93.19236755371094, 'vector': 300, 'window': 25, 'hs_val': 0, 'train_time_mean': 0.015184640884399414, 'train_time_std': 0.0018233644507411435}\n",
            "Word2vec model #54: {'compute_loss': 89.70285034179688, 'vector': 300, 'window': 30, 'hs_val': 0, 'train_time_mean': 0.010653972625732422, 'train_time_std': 0.007533657280178939}\n",
            "Word2vec model #55: {'compute_loss': 119.30368041992188, 'vector': 300, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.011131048202514648, 'train_time_std': 0.007226775087926454}\n",
            "Word2vec model #56: {'compute_loss': 137.74288940429688, 'vector': 300, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.017031749089558918, 'train_time_std': 0.0005640755951811062}\n",
            "Word2vec model #57: {'compute_loss': 186.40870666503906, 'vector': 300, 'window': 20, 'hs_val': 1, 'train_time_mean': 0.012351195017496744, 'train_time_std': 0.00893697928463795}\n",
            "Word2vec model #58: {'compute_loss': 145.451416015625, 'vector': 300, 'window': 25, 'hs_val': 1, 'train_time_mean': 0.015447696050008139, 'train_time_std': 0.0044103150216686215}\n",
            "Word2vec model #59: {'compute_loss': 137.74288940429688, 'vector': 300, 'window': 30, 'hs_val': 1, 'train_time_mean': 0.010881423950195312, 'train_time_std': 0.007045360404302337}\n",
            "Word2vec model #60: {'compute_loss': 28.938350677490234, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.01463643709818522, 'train_time_std': 0.006633797805190531}\n",
            "Word2vec model #61: {'compute_loss': 43.07927322387695, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.007886171340942383, 'train_time_std': 0.005693903644350309}\n",
            "Word2vec model #62: {'compute_loss': 25.393983840942383, 'vector': 100, 'window': 20, 'hs_val': 0, 'train_time_mean': 0.013974587122599283, 'train_time_std': 0.005504904232762845}\n",
            "Word2vec model #63: {'compute_loss': 35.30968475341797, 'vector': 100, 'window': 25, 'hs_val': 0, 'train_time_mean': 0.007707357406616211, 'train_time_std': 0.006821117100456724}\n",
            "Word2vec model #64: {'compute_loss': 43.07927322387695, 'vector': 100, 'window': 30, 'hs_val': 0, 'train_time_mean': 0.013427495956420898, 'train_time_std': 0.002928175152724913}\n",
            "Word2vec model #65: {'compute_loss': 39.534912109375, 'vector': 100, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.008845090866088867, 'train_time_std': 0.0068502752120391175}\n",
            "Word2vec model #66: {'compute_loss': 58.63671875, 'vector': 100, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.010064284006754557, 'train_time_std': 0.008547979492668929}\n",
            "Word2vec model #67: {'compute_loss': 35.27314376831055, 'vector': 100, 'window': 20, 'hs_val': 1, 'train_time_mean': 0.00959324836730957, 'train_time_std': 0.0020842047178099036}\n",
            "Word2vec model #68: {'compute_loss': 47.33494567871094, 'vector': 100, 'window': 25, 'hs_val': 1, 'train_time_mean': 0.007949908574422201, 'train_time_std': 0.005057319337754685}\n",
            "Word2vec model #69: {'compute_loss': 58.63671875, 'vector': 100, 'window': 30, 'hs_val': 1, 'train_time_mean': 0.010510603586832682, 'train_time_std': 0.007432535169783718}\n",
            "Word2vec model #70: {'compute_loss': 28.938350677490234, 'vector': 200, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.01353891690572103, 'train_time_std': 0.0102164573570054}\n",
            "Word2vec model #71: {'compute_loss': 43.085365295410156, 'vector': 200, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.015953938166300457, 'train_time_std': 0.0008747289756594733}\n",
            "Word2vec model #72: {'compute_loss': 25.393983840942383, 'vector': 200, 'window': 20, 'hs_val': 0, 'train_time_mean': 0.010349035263061523, 'train_time_std': 0.006313875035417055}\n",
            "Word2vec model #73: {'compute_loss': 35.315773010253906, 'vector': 200, 'window': 25, 'hs_val': 0, 'train_time_mean': 0.01683632532755534, 'train_time_std': 0.008688615403601326}\n",
            "Word2vec model #74: {'compute_loss': 43.085365295410156, 'vector': 200, 'window': 30, 'hs_val': 0, 'train_time_mean': 0.011126995086669922, 'train_time_std': 0.008669951982735943}\n",
            "Word2vec model #75: {'compute_loss': 39.5288200378418, 'vector': 200, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.010693073272705078, 'train_time_std': 0.007564990572260474}\n",
            "Word2vec model #76: {'compute_loss': 58.63063049316406, 'vector': 200, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.012064297993977865, 'train_time_std': 0.0028490641412739705}\n",
            "Word2vec model #77: {'compute_loss': 35.267051696777344, 'vector': 200, 'window': 20, 'hs_val': 1, 'train_time_mean': 0.007949749628702799, 'train_time_std': 0.006025480086962668}\n",
            "Word2vec model #78: {'compute_loss': 47.3227653503418, 'vector': 200, 'window': 25, 'hs_val': 1, 'train_time_mean': 0.007592201232910156, 'train_time_std': 0.006180113659964245}\n",
            "Word2vec model #79: {'compute_loss': 58.63063049316406, 'vector': 200, 'window': 30, 'hs_val': 1, 'train_time_mean': 0.01133879025777181, 'train_time_std': 0.008019080689188399}\n",
            "Word2vec model #80: {'compute_loss': 28.944440841674805, 'vector': 300, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.008176883061726889, 'train_time_std': 0.010723271750188059}\n",
            "Word2vec model #81: {'compute_loss': 43.085365295410156, 'vector': 300, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.010937690734863281, 'train_time_std': 0.007702757623052196}\n",
            "Word2vec model #82: {'compute_loss': 25.393983840942383, 'vector': 300, 'window': 20, 'hs_val': 0, 'train_time_mean': 0.008721590042114258, 'train_time_std': 0.0065286309490011395}\n",
            "Word2vec model #83: {'compute_loss': 35.32186508178711, 'vector': 300, 'window': 25, 'hs_val': 0, 'train_time_mean': 0.011296510696411133, 'train_time_std': 0.007989973080691999}\n",
            "Word2vec model #84: {'compute_loss': 43.085365295410156, 'vector': 300, 'window': 30, 'hs_val': 0, 'train_time_mean': 0.007684071858723958, 'train_time_std': 0.010866918636856859}\n",
            "Word2vec model #85: {'compute_loss': 39.54100036621094, 'vector': 300, 'window': 10, 'hs_val': 1, 'train_time_mean': 0.008781909942626953, 'train_time_std': 0.002593631323108033}\n",
            "Word2vec model #86: {'compute_loss': 58.6428108215332, 'vector': 300, 'window': 15, 'hs_val': 1, 'train_time_mean': 0.010762453079223633, 'train_time_std': 0.007621945696181405}\n",
            "Word2vec model #87: {'compute_loss': 35.27314376831055, 'vector': 300, 'window': 20, 'hs_val': 1, 'train_time_mean': 0.00812967618306478, 'train_time_std': 0.009756393524042556}\n",
            "Word2vec model #88: {'compute_loss': 47.34712219238281, 'vector': 300, 'window': 25, 'hs_val': 1, 'train_time_mean': 0.010416110356648764, 'train_time_std': 0.007365302282852373}\n",
            "Word2vec model #89: {'compute_loss': 58.6428108215332, 'vector': 300, 'window': 30, 'hs_val': 1, 'train_time_mean': 0.009485960006713867, 'train_time_std': 0.006009152769316016}\n",
            "Word2vec model #90: {'compute_loss': 2.8208770751953125, 'vector': 100, 'window': 10, 'hs_val': 0, 'train_time_mean': 0.010817845662434896, 'train_time_std': 0.00730077090886425}\n",
            "Word2vec model #91: {'compute_loss': 2.1156578063964844, 'vector': 100, 'window': 15, 'hs_val': 0, 'train_time_mean': 0.008576154708862305, 'train_time_std': 0.009170146356470345}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-21365 (_worker_loop):\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\e312995\\AppData\\Local\\anaconda3\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"c:\\Users\\e312995\\AppData\\Local\\anaconda3\\Lib\\threading.py\", line 982, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"c:\\Users\\e312995\\AppData\\Local\\anaconda3\\Lib\\site-packages\\gensim\\models\\word2vec.py\", line 1166, in _worker_loop\n",
            "    tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\e312995\\AppData\\Local\\anaconda3\\Lib\\site-packages\\gensim\\models\\word2vec.py\", line 957, in _do_train_job\n",
            "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"gensim\\models\\word2vec_inner.pyx\", line 649, in gensim.models.word2vec_inner.train_batch_cbow\n",
            "TypeError: Cannot convert list to numpy.ndarray\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2vec model #92: {'compute_loss': 1.4104385375976562, 'vector': 100, 'window': 20, 'hs_val': 0, 'train_time_mean': 0.011245965957641602, 'train_time_std': 0.00472805980847306}\n",
            "Word2vec model #93: {'compute_loss': 1.4104385375976562, 'vector': 100, 'window': 25, 'hs_val': 0, 'train_time_mean': 0.00864561398824056, 'train_time_std': 0.006790837919685372}\n",
            "Word2vec model #94: {'compute_loss': 2.1156578063964844, 'vector': 100, 'window': 30, 'hs_val': 0, 'train_time_mean': 0.010761260986328125, 'train_time_std': 0.0076187747740493784}\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "train_time_values = []\n",
        "seed_val = 42\n",
        "\n",
        "hs_values = [0, 1]\n",
        "vector_values= [100,200,300]\n",
        "window_values= [10,15, 20, 25, 30]\n",
        "\n",
        "for data in text_data_cleaned:\n",
        "    for vector in vector_values:\n",
        "        for hs_val in hs_values:\n",
        "            for window in window_values:\n",
        "                time_taken_list = []\n",
        "                for i in range(3):\n",
        "                    start_time = time.time()\n",
        "                    w2v_model = Word2Vec(\n",
        "                        data,\n",
        "                        compute_loss=True,\n",
        "                        window= window,\n",
        "                        vector_size=vector,\n",
        "                        hs=hs_val,\n",
        "                        seed=seed_val,\n",
        "                    )\n",
        "                    time_taken_list.append(time.time() - start_time)\n",
        "\n",
        "                time_taken_list = np.array(time_taken_list)\n",
        "                time_mean = np.mean(time_taken_list)\n",
        "                time_std = np.std(time_taken_list)\n",
        "\n",
        "                model_result = {\n",
        "                    \n",
        "                    'compute_loss': w2v_model.get_latest_training_loss(),\n",
        "                    'vector': vector,\n",
        "                    'window': window,\n",
        "                    'hs_val': hs_val,\n",
        "                    'train_time_mean': time_mean,\n",
        "                    'train_time_std': time_std,\n",
        "                }\n",
        "                print(\"Word2vec model #%i: %s\" % (len(train_time_values), model_result))\n",
        "                train_time_values.append(model_result)\n",
        "\n",
        "train_times_table = pd.DataFrame(train_time_values)\n",
        "train_times_table = train_times_table.sort_values(\n",
        "    by=['train_data',  'hs', 'compute_loss'],\n",
        "    ascending=[False, False, False],\n",
        ")\n",
        "print(train_times_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d220f70",
      "metadata": {},
      "source": [
        "I will select hs=0, vector size= 100 & window=20 for the final model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "8cab2663",
      "metadata": {},
      "outputs": [],
      "source": [
        "#final model\n",
        "phrases_model_2=Word2Vec(sentences=text_data_cleaned,min_count=1, sg=0, window=20, workers=8, vector_size=100, compute_loss=True)\n",
        "\n",
        "#saving the model\n",
        "phrases_model_2.save('../Models/Word2Vec/phrases_model_new(op2).bin')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf380ee4",
      "metadata": {},
      "source": [
        "### <a id='toc3_1_3_'></a>[Vectorization & Recommendation](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6d860468",
      "metadata": {},
      "outputs": [],
      "source": [
        "def recommender_text(text_input):\n",
        "\n",
        "    user_input= parser_text(text_input)\n",
        "\n",
        "    # Mean Embeddings for User Input\n",
        "    user_mean_vector =np.mean([phrases_model_2.wv[user_text] for user_text in user_input if user_text in phrases_model_2.wv] or [np.zeros(100)], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "    # check if user_mean_vector contains NaN values\n",
        "    if np.isnan(user_mean_vector).any():\n",
        "        print(\"User input vectors contain NaN values.\")\n",
        "\n",
        "\n",
        "    else:\n",
        "\n",
        "        # mean ingredient vectors for each recipe\n",
        "        text_vectors = [np.mean([phrases_model_2.wv[sub_text] for sub_text in text if sub_text in phrases_model_2.wv] or [np.zeros(100)], axis=0) for text in text_data_cleaned]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Check if any recipe vector contains NaN values\n",
        "        if not text_vectors:\n",
        "            print('nothing obtained for recipe vectors')\n",
        "\n",
        "        else:\n",
        "            \n",
        "            # cosine similarity between user mean vector and recipe mean vectors\n",
        "            cosine_similarities_text= cosine_similarity([user_mean_vector], text_vectors)\n",
        "\n",
        "\n",
        "            # indices of top N most similar recipes\n",
        "            top_recipes = np.argsort(cosine_similarities_text[0])[::-1][:5]\n",
        "\n",
        "\n",
        "\n",
        "            recommendation= pd.DataFrame( columns=['title','ingredients', 'description', 'keywords', 'category', 'score'] ) #dataframe with columns\n",
        "\n",
        "    \n",
        "            for i in top_recipes: #defining the data for each recommendation\n",
        "\n",
        "                \n",
        "                title = recipes['Name'].iloc[i],\n",
        "                description= recipes['Description'].iloc[i,]\n",
        "                keywords = recipes['Keywords'].iloc[i]\n",
        "                category= recipes['RecipeCategory'].iloc[i]\n",
        "                ingredients = recipes['RecipeIngredientParts'].iloc[i]\n",
        "                score= cosine_similarities_text[0][i]\n",
        "                # recommendation = recommendation.concat([\n",
        "                #                     {'title': title, \n",
        "                #                     'description': description,\n",
        "                #                     'ingredients': ingredients, \n",
        "                #                     'keywords' : keywords, \n",
        "                #                     'category' : category, \n",
        "                #                     'score': score}], \n",
        "                #                         ignore_index=True)\n",
        "                recommendation = pd.concat([recommendation,pd.DataFrame(\n",
        "                                    {'title': [title], \n",
        "                                    'description': [description],\n",
        "                                    'ingredients': [ingredients], \n",
        "                                    'keywords' : [keywords], \n",
        "                                    'category' : [category], \n",
        "                                    'score': [score]})], \n",
        "                                        ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return recommendation\n",
        "\n",
        "       \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "1706f346",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\e312995\\AppData\\Local\\Temp\\ipykernel_30044\\3192812213.py:59: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  recommendation = pd.concat([recommendation,pd.DataFrame(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>description</th>\n",
              "      <th>keywords</th>\n",
              "      <th>category</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Cabbage Soup,)</td>\n",
              "      <td>butter, onion, turnip, cabbage, salt, pepper, ...</td>\n",
              "      <td>Make and share this Cabbage Soup recipe from F...</td>\n",
              "      <td>Inexpensive</td>\n",
              "      <td>&lt; 30 Mins</td>\n",
              "      <td>0.983764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(Cabbage and Mushroom Soup,)</td>\n",
              "      <td>vegetable broth, onions, garlic cloves, cabbag...</td>\n",
              "      <td>Make and share this Cabbage and Mushroom Soup ...</td>\n",
              "      <td>Easy</td>\n",
              "      <td>&lt; 4 Hours</td>\n",
              "      <td>0.855485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Ukrainian Pea Soup Horokhivka,)</td>\n",
              "      <td>water, salt pork, ham fat, onion, celery, carr...</td>\n",
              "      <td>Make and share this Ukrainian Pea Soup Horokhi...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>European</td>\n",
              "      <td>0.820917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Cabbage Soup,)</td>\n",
              "      <td>lean ground beef, onion, cabbage, diced tomato...</td>\n",
              "      <td>Make and share this Cabbage Soup recipe from F...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt; 4 Hours</td>\n",
              "      <td>0.819991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(Pea Soup With Doughboys,)</td>\n",
              "      <td>salt pork, ham bone, water, onion, celery, pot...</td>\n",
              "      <td>This recipe is from Extending the Table and is...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Canadian</td>\n",
              "      <td>0.812112</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              title  \\\n",
              "0                   (Cabbage Soup,)   \n",
              "1      (Cabbage and Mushroom Soup,)   \n",
              "2  (Ukrainian Pea Soup Horokhivka,)   \n",
              "3                   (Cabbage Soup,)   \n",
              "4        (Pea Soup With Doughboys,)   \n",
              "\n",
              "                                         ingredients  \\\n",
              "0  butter, onion, turnip, cabbage, salt, pepper, ...   \n",
              "1  vegetable broth, onions, garlic cloves, cabbag...   \n",
              "2  water, salt pork, ham fat, onion, celery, carr...   \n",
              "3  lean ground beef, onion, cabbage, diced tomato...   \n",
              "4  salt pork, ham bone, water, onion, celery, pot...   \n",
              "\n",
              "                                         description     keywords   category  \\\n",
              "0  Make and share this Cabbage Soup recipe from F...  Inexpensive  < 30 Mins   \n",
              "1  Make and share this Cabbage and Mushroom Soup ...         Easy  < 4 Hours   \n",
              "2  Make and share this Ukrainian Pea Soup Horokhi...          NaN   European   \n",
              "3  Make and share this Cabbage Soup recipe from F...          NaN  < 4 Hours   \n",
              "4  This recipe is from Extending the Table and is...          NaN   Canadian   \n",
              "\n",
              "      score  \n",
              "0  0.983764  \n",
              "1  0.855485  \n",
              "2  0.820917  \n",
              "3  0.819991  \n",
              "4  0.812112  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# user Input Processing\n",
        "text_input = 'cabbage soup'  # user's input\n",
        "\n",
        "recommender_text(text_input)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "214da573",
      "metadata": {},
      "source": [
        "# <a id='toc4_'></a>[Option 3 : Search by Ingredients & Keywords both together](#toc0_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "962d7636",
      "metadata": {},
      "source": [
        "## <a id='toc4_1_'></a>[Tokenization](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "48a942a0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Low-Fat Berry Blue Frozen Dessert,Frozen Desserts,Dessert, Low Protein, Low Cholesterol, Healthy, Free Of..., Summer, Weeknight, Freezer, Easy,blueberries, granulated sugar, vanilla yogurt, lemon juice'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#combining the 4 columns data to one\n",
        "recipes['text_data_all']= recipes[['Name', 'RecipeCategory', 'Keywords', 'RecipeIngredientParts']].astype(str).agg(','.join, axis=1) \n",
        "#sanity check\n",
        "recipes['text_data_all'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "bd7d884b",
      "metadata": {},
      "outputs": [],
      "source": [
        "#parser\n",
        "def parser_text(input_keys): #function\n",
        "\n",
        "\n",
        "    # Defining measuring units\n",
        "    remove_ = {'oil', 'salt', 'pepper' , 'mins'}\n",
        "\n",
        "\n",
        "    # Defining measuring units\n",
        "    measuring_words = ['ml', 'mL', 'milliliter', 'millilitre', 'cc', 'cubic centimeter', 'l', 'L', 'liter', 'litre', 'dl',\n",
        "                   'dL', 'deciliter', 'decilitre', 'teaspoon', 't', 'tsp.', 'tablespoon', 'T', 'tbl', 'tbs', 'tbsp',\n",
        "                   'fluid ounce', 'fl oz', 'gill', 'cup', 'c', 'pint', 'p', 'pt', 'fl pt', 'quart', 'q', 'qt', 'fl qt',\n",
        "                   'gallon', 'g', 'gal', 'g', 'milligram', 'milligramme', 'g', 'gram', 'gramme', 'kg', 'kilogram',\n",
        "                   'kilogramme', 'pound', 'lb', 'ounce', 'oz', 'mm', 'milimeter', 'millimetre', 'cm', 'centimeter',\n",
        "                   'centimetre', 'm', 'meter', 'metre', 'inch', 'in', 'yard', '°C', 'degree celsius', '°F', 'Farenheit', 'tsp']\n",
        "\n",
        "    cleaned_ingredients_all_recipes = []\n",
        "    \n",
        "    for each_ingredient_list in input_keys:\n",
        "            comma_list = re.split(',', each_ingredient_list)  # splitting the ingredients by commas\n",
        "\n",
        "\n",
        "            cleaned_ingredients = []  # new list to store cleaned ingredients for a single recipe\n",
        "\n",
        "\n",
        "            lemmatizer = WordNetLemmatizer()  # lemmatize\n",
        "\n",
        "\n",
        "            for each_word_set in comma_list:\n",
        "                items = [word.lower() for word in re.findall(r'\\b\\w+\\b', each_word_set)]  # Extract individual words and convert to lowercase\n",
        "\n",
        "\n",
        "                items = [word for word in items if word.isalpha()]  # filtering only letters\n",
        "\n",
        "                items = [lemmatizer.lemmatize(word) for word in items]  # lemmatizing\n",
        "\n",
        "\n",
        "                items = [word for word in items if word not in ENGLISH_STOP_WORDS]  # removing stop words\n",
        "\n",
        "\n",
        "                items = [word for word in items if word not in measuring_words]  # removing measuring words\n",
        "\n",
        "\n",
        "                items = [word for word in items if word not in remove_]\n",
        "\n",
        "\n",
        "                if items:\n",
        "                    cleaned_ingredients.extend(items)\n",
        "\n",
        "\n",
        "            cleaned_ingredients_all_recipes.append(cleaned_ingredients)\n",
        "\n",
        "    return(cleaned_ingredients_all_recipes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58f7813f",
      "metadata": {},
      "source": [
        "## <a id='toc4_2_'></a>[Modeling](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "0696914e",
      "metadata": {},
      "outputs": [],
      "source": [
        "text_data_all= recipes['text_data_all']\n",
        "text_data_all_cleaned=parser_text(text_data_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "df305aa3",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8143415.0"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#vector size 100\n",
        "phrases_model_3=Word2Vec(sentences=text_data_all_cleaned,min_count=1, sg=0, window=35, workers=8, vector_size=200, compute_loss=True) #word2vec model, used min_count=1 to avoid any ingredient being missed out\n",
        "phrases_model_3.get_latest_training_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "b2ee106a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8377434.0"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "phrases_model_3=Word2Vec(sentences=text_data_all_cleaned,min_count=1, sg=0, window=35, workers=8, vector_size=100, compute_loss=True) #word2vec model, used min_count=1 to avoid any ingredient being missed out\n",
        "phrases_model_3.get_latest_training_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "f2f76728",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7979320.0"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "phrases_model_3=Word2Vec(sentences=text_data_all_cleaned,min_count=1, sg=0, window=35, workers=8, vector_size=300, compute_loss=True) #word2vec model, used min_count=1 to avoid any ingredient being missed out\n",
        "phrases_model_3.get_latest_training_loss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ad3884b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import time   \n",
        "train_time_values = []\n",
        "seed_val = 42\n",
        "\n",
        "hs_values = [0, 1]\n",
        "vector_values= [100,200,300]\n",
        "window_values= [10, 20, 25, 30]\n",
        "\n",
        "\n",
        "for data in text_data_all_cleaned:\n",
        "    for vector in vector_values:\n",
        "        for hs_val in hs_values:\n",
        "            for window in window_values:\n",
        "                time_taken_list = []\n",
        "                for i in range(3):\n",
        "                    start_time = time.time()\n",
        "                    w2v_model = Word2Vec(\n",
        "                        data,\n",
        "                        compute_loss=True,\n",
        "                        window= window,\n",
        "                        vector_size=vector,\n",
        "                        hs=hs_val,\n",
        "                        seed=seed_val,\n",
        "                    )\n",
        "                    time_taken_list.append(time.time() - start_time)\n",
        "\n",
        "                time_taken_list = np.array(time_taken_list)\n",
        "                time_mean = np.mean(time_taken_list)\n",
        "                time_std = np.std(time_taken_list)\n",
        "\n",
        "                model_result = {\n",
        "                    \n",
        "                    'compute_loss': w2v_model.get_latest_training_loss(),\n",
        "                    'vector': vector,\n",
        "                    'window': window,\n",
        "                    'hs_val': hs_val,\n",
        "                    'train_time_mean': time_mean,\n",
        "                    'train_time_std': time_std,\n",
        "                }\n",
        "                print(\"Word2vec model #%i: %s\" % (len(train_time_values), model_result))\n",
        "                train_time_values.append(model_result)\n",
        "\n",
        "train_times_table = pd.DataFrame(train_time_values)\n",
        "train_times_table = train_times_table.sort_values(\n",
        "    by=['train_data',  'hs', 'compute_loss'],\n",
        "    ascending=[False, False, False],\n",
        ")\n",
        "print(train_times_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "61abb40f",
      "metadata": {},
      "outputs": [],
      "source": [
        "phrases_model_3=Word2Vec(sentences=text_data_all_cleaned,min_count=1, sg=0, window=30, workers=8, vector_size=100, compute_loss=True) #word2vec model, used min_count=1 to avoid any ingredient being missed out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aa117de",
      "metadata": {},
      "source": [
        "## <a id='toc4_3_'></a>[Vectorization & Recommendation](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "f5f08d87",
      "metadata": {},
      "outputs": [],
      "source": [
        "def recommender_text_all(text_input):\n",
        "\n",
        "    user_input= parser(text_input)\n",
        "\n",
        "    # Mean Embeddings for User Input\n",
        "    user_mean_vector =np.mean([phrases_model_3.wv[user_text] for user_text in user_input if user_text in phrases_model_3.wv] or [np.zeros(100)], axis=0)\n",
        "\n",
        "\n",
        "\n",
        "    # check if user_mean_vector contains NaN values\n",
        "    if np.isnan(user_mean_vector).any():\n",
        "        print(\"User input vectors contain NaN values.\")\n",
        "\n",
        "\n",
        "    else:\n",
        "\n",
        "        # mean ingredient vectors for each recipe\n",
        "        text_vectors = [np.mean([phrases_model_3.wv[sub_text] for sub_text in text if sub_text in phrases_model_3.wv] or [np.zeros(100)], axis=0) for text in text_data_all_cleaned]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Check if any recipe vector contains NaN values\n",
        "        if not text_vectors:\n",
        "            print('nothing obtained for recipe vectors')\n",
        "\n",
        "        else:\n",
        "            \n",
        "            # cosine similarity between user mean vector and recipe mean vectors\n",
        "            cosine_similarities_text= cosine_similarity([user_mean_vector], text_vectors)\n",
        "\n",
        "\n",
        "            # indices of top N most similar recipes\n",
        "            top_recipes = np.argsort(cosine_similarities_text[0])[::-1][:5]\n",
        "\n",
        "\n",
        "\n",
        "            recommendation= pd.DataFrame( columns=['title','ingredients', 'description', 'keywords', 'category', 'score'] ) #dataframe with columns\n",
        "\n",
        "    \n",
        "            for i in top_recipes: #defining the data for each recommendation\n",
        "\n",
        "                \n",
        "                title = recipes['Name'].iloc[i],\n",
        "                description= recipes['Description'].iloc[i,]\n",
        "                keywords = recipes['Keywords'].iloc[i]\n",
        "                category= recipes['RecipeCategory'].iloc[i]\n",
        "                ingredients = recipes['RecipeIngredientParts'].iloc[i]\n",
        "                score= cosine_similarities_text[0][i]\n",
        "                recommendation = pd.concat([recommendation,pd.DataFrame(\n",
        "                                    {'title': [title], \n",
        "                                    'description': [description],\n",
        "                                    'ingredients': [ingredients], \n",
        "                                    'keywords' : [keywords], \n",
        "                                    'category' : [category], \n",
        "                                    'score': [score]})], \n",
        "                                        ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return recommendation\n",
        "\n",
        "       \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "58c5c257",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\e312995\\AppData\\Local\\Temp\\ipykernel_30044\\1809556674.py:51: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  recommendation = pd.concat([recommendation,pd.DataFrame(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>description</th>\n",
              "      <th>keywords</th>\n",
              "      <th>category</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Maghero's Soup,)</td>\n",
              "      <td>cabbage, cabbage, carrots, celery ribs, onion,...</td>\n",
              "      <td>Make and share this Maghero's Soup recipe from...</td>\n",
              "      <td>Beans, European, &lt; 4 Hours</td>\n",
              "      <td>Clear Soup</td>\n",
              "      <td>0.803425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(Sausage Cabbage Soup,)</td>\n",
              "      <td>cabbage, chicken broth, pepper, salt, flour, m...</td>\n",
              "      <td>Make and share this Sausage Cabbage Soup recip...</td>\n",
              "      <td>&lt; 4 Hours, Easy</td>\n",
              "      <td>Clear Soup</td>\n",
              "      <td>0.801862</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(Cabbage Soup,)</td>\n",
              "      <td>butter, onion, turnip, cabbage, salt, pepper, ...</td>\n",
              "      <td>Make and share this Cabbage Soup recipe from F...</td>\n",
              "      <td>Inexpensive</td>\n",
              "      <td>&lt; 30 Mins</td>\n",
              "      <td>0.788275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Diet Cabbage Soup,)</td>\n",
              "      <td>carrots, zucchini, bell peppers, celery ribs, ...</td>\n",
              "      <td>My mom wanted to try this diet, and made a hug...</td>\n",
              "      <td>Weeknight, Stove Top, &lt; 4 Hours</td>\n",
              "      <td>Vegetable</td>\n",
              "      <td>0.786210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(Autumn Harvest Root Vegetable Soup,)</td>\n",
              "      <td>carrots, parsnips, cabbage, onion, celery ribs...</td>\n",
              "      <td>Make and share this Autumn Harvest Root Vegeta...</td>\n",
              "      <td>Vegetable, &lt; 60 Mins</td>\n",
              "      <td>Clear Soup</td>\n",
              "      <td>0.781178</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   title  \\\n",
              "0                      (Maghero's Soup,)   \n",
              "1                (Sausage Cabbage Soup,)   \n",
              "2                        (Cabbage Soup,)   \n",
              "3                   (Diet Cabbage Soup,)   \n",
              "4  (Autumn Harvest Root Vegetable Soup,)   \n",
              "\n",
              "                                         ingredients  \\\n",
              "0  cabbage, cabbage, carrots, celery ribs, onion,...   \n",
              "1  cabbage, chicken broth, pepper, salt, flour, m...   \n",
              "2  butter, onion, turnip, cabbage, salt, pepper, ...   \n",
              "3  carrots, zucchini, bell peppers, celery ribs, ...   \n",
              "4  carrots, parsnips, cabbage, onion, celery ribs...   \n",
              "\n",
              "                                         description  \\\n",
              "0  Make and share this Maghero's Soup recipe from...   \n",
              "1  Make and share this Sausage Cabbage Soup recip...   \n",
              "2  Make and share this Cabbage Soup recipe from F...   \n",
              "3  My mom wanted to try this diet, and made a hug...   \n",
              "4  Make and share this Autumn Harvest Root Vegeta...   \n",
              "\n",
              "                          keywords    category     score  \n",
              "0       Beans, European, < 4 Hours  Clear Soup  0.803425  \n",
              "1                  < 4 Hours, Easy  Clear Soup  0.801862  \n",
              "2                      Inexpensive   < 30 Mins  0.788275  \n",
              "3  Weeknight, Stove Top, < 4 Hours   Vegetable  0.786210  \n",
              "4             Vegetable, < 60 Mins  Clear Soup  0.781178  "
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "user_input= 'soup, cabbage, carrot, onion'\n",
        "recommender_text_all(user_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "03e9d1e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "recipes.to_csv('../Docs/Datasets/recipes_streamlit.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2439d012",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
